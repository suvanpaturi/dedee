{
  "results": [
    {
      "query": "Who was Cixi's son?",
      "predicted_response": "Cixi's son was Emperor Tongzhi, born as Zaichun.",
      "method": "global-llm",
      "actual_response": "Tongzhi",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.170000854879618e-05,
        "tree_retrieval": 0.006683220039121807,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 2.0183422910049558,
      "bert_score": 0.8350028395652771,
      "f1_score": 0.2222222222222222,
      "rouge_score": 0.19999999999999998,
      "bleurt_score": -0.7247259020805359
    },
    {
      "query": "In kilometers, how long is the Staten Island Ferry route?",
      "predicted_response": "8.4",
      "method": "exact-match",
      "actual_response": "8.4",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8999987989664078e-05,
        "tree_retrieval": 0.331346187973395,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.5254699171055108,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9597485661506653
    },
    {
      "query": "What was the name of the miner's leader that was blamed for the strike?",
      "predicted_response": "Arthur Scargill",
      "method": "exact-match",
      "actual_response": "Arthur Scargill",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.430006422102451e-05,
        "tree_retrieval": 0.0862559339730069,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23934858315624297,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9373068809509277
    },
    {
      "query": "How much was allocated?",
      "predicted_response": "\u20b9 52.7 million",
      "method": "exact-match",
      "actual_response": "\u20b9 52.7 million",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.070000093430281e-05,
        "tree_retrieval": 0.08356906101107597,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.26779912505298853,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0584653615951538
    },
    {
      "query": "When did Virginia adopt The Principle of Partus Sequitur Ventrem?",
      "predicted_response": "1662",
      "method": "exact-match",
      "actual_response": "1662",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.3299940191209316e-05,
        "tree_retrieval": 0.08414676203392446,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.24584995792247355,
      "bert_score": 0.9999996423721313,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8003727197647095
    },
    {
      "query": "When did the Borders Books open up in Ann Arbor?",
      "predicted_response": "1971",
      "method": "exact-match",
      "actual_response": "1971",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8201029635965824e-05,
        "tree_retrieval": 0.08657286607194692,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23952258308418095,
      "bert_score": 1.0000005960464478,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8586664795875549
    },
    {
      "query": "What has the research that has been conducted for the influence of genetics made many people think?",
      "predicted_response": "that biology and environment factors play a complex role in forming it",
      "method": "exact-match",
      "actual_response": "that biology and environment factors play a complex role in forming it",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.0400038920342922e-05,
        "tree_retrieval": 0.0853889639256522,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.32648645900189877,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0501559972763062
    },
    {
      "query": "How big was the crew of a bomber?",
      "predicted_response": "four to five crewmen",
      "method": "exact-match",
      "actual_response": "four to five crewmen",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8999987989664078e-05,
        "tree_retrieval": 0.08670976699795574,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.30131325009278953,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.1010231971740723
    },
    {
      "query": "What, typically, is the speed of the second movement in a classical piece?",
      "predicted_response": "slow",
      "method": "exact-match",
      "actual_response": "slow",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.060000017285347e-05,
        "tree_retrieval": 0.08583916502539068,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2648133330512792,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8838905096054077
    },
    {
      "query": "Along with the Marianas, where do typhoons that begin in the Marshalls sometimes terminate?",
      "predicted_response": "the Philippines",
      "method": "exact-match",
      "actual_response": "the Philippines",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9799994081258774e-05,
        "tree_retrieval": 0.08729966799728572,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2410460419487208,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9783362150192261
    },
    {
      "query": "How much of Nigeria's male population can read?",
      "predicted_response": "75.7%",
      "method": "exact-match",
      "actual_response": "75.7%",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9199989512562752e-05,
        "tree_retrieval": 0.08669276698492467,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23919283295981586,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0238531827926636
    },
    {
      "query": "The true diversity within the insect species remains what?",
      "predicted_response": "uncertain",
      "method": "exact-match",
      "actual_response": "uncertain",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.6899971999228e-05,
        "tree_retrieval": 0.08706536795943975,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.24116083304397762,
      "bert_score": 1.0000008344650269,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9613901972770691
    },
    {
      "query": "What school does not include the Mahayava scriptures in its canon?",
      "predicted_response": "the Theravada",
      "method": "exact-match",
      "actual_response": "the Theravada",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.3600063286721706e-05,
        "tree_retrieval": 0.08513326302636415,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.239396832883358,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9828547239303589
    },
    {
      "query": "How much rain does the Sahel savannah area get per year?",
      "predicted_response": "less than 500 millimetres (20 in)",
      "method": "exact-match",
      "actual_response": "less than 500 millimetres (20 in)",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9199989512562752e-05,
        "tree_retrieval": 0.08402026200201362,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23585404083132744,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.1119412183761597
    },
    {
      "query": "What are the financial districts of London known as?",
      "predicted_response": "the City of London and Canary Wharf",
      "method": "exact-match",
      "actual_response": "the City of London and Canary Wharf",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.900103572756052e-05,
        "tree_retrieval": 0.08496716304216534,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23846499994397163,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0287798643112183
    },
    {
      "query": "Approximately how many old masters works are included in the V&A collection?",
      "predicted_response": "2,000",
      "method": "exact-match",
      "actual_response": "2,000",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.7999980375170708e-05,
        "tree_retrieval": 0.08610376494470984,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2392659578472376,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0497397184371948
    },
    {
      "query": "By coping the Arsenal team kit exactly, what nickname was given to Sporting Clube de Braga?",
      "predicted_response": "Os Arsenalistas",
      "method": "exact-match",
      "actual_response": "Os Arsenalistas",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.749997217208147e-05,
        "tree_retrieval": 0.08363816095516086,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2351286660414189,
      "bert_score": 0.9999996423721313,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9606010913848877
    },
    {
      "query": "Which year was royal assent last withheld in the UK?",
      "predicted_response": "1708",
      "method": "exact-match",
      "actual_response": "1708",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.7600908651947975e-05,
        "tree_retrieval": 0.08631676505319774,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23991716606542468,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.7942100167274475
    },
    {
      "query": "Children who have experienced sever diarrhea are more likely to have what effect?",
      "predicted_response": "significantly lower scores on a series of tests of intelligence",
      "method": "exact-match",
      "actual_response": "significantly lower scores on a series of tests of intelligence",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.179992876946926e-05,
        "tree_retrieval": 0.08497806394007057,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2374057499691844,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0820969343185425
    },
    {
      "query": "How is the recognized official language of Burma displayed ? ",
      "predicted_response": "It is written in a script consisting of circular and semi-circular letters",
      "method": "exact-match",
      "actual_response": "It is written in a script consisting of circular and semi-circular letters",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.859998494386673e-05,
        "tree_retrieval": 0.08408556203357875,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2703335410915315,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0656276941299438
    },
    {
      "query": "What dis the new term, post-punk, cover?",
      "predicted_response": "groups moving beyond punk's sonic template into disparate areas",
      "method": "exact-match",
      "actual_response": "groups moving beyond punk's sonic template into disparate areas",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.029999788850546e-05,
        "tree_retrieval": 0.08376706100534648,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2353267080616206,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0577574968338013
    },
    {
      "query": "What did a study done by Elizabeth Loftus and John palmer show?",
      "predicted_response": "that when people were provided with misleading information they tended to misremember, a phenomenon known as the misinformation effect.",
      "method": "exact-match",
      "actual_response": "that when people were provided with misleading information they tended to misremember, a phenomenon known as the misinformation effect.",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8199981898069382e-05,
        "tree_retrieval": 0.08667916699778289,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2380828750319779,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0310109853744507
    },
    {
      "query": "What well-known archeologist believed the Amazon didn't have many inhabitants?",
      "predicted_response": "Betty Meggers",
      "method": "exact-match",
      "actual_response": "Betty Meggers",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.950010821223259e-05,
        "tree_retrieval": 0.08477316307835281,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.3420457090251148,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9067932367324829
    },
    {
      "query": "What are there no longer limitations on since 1990?",
      "predicted_response": "residency registration",
      "method": "exact-match",
      "actual_response": "residency registration",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0099996365606785e-05,
        "tree_retrieval": 0.08625376608688384,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23805929184891284,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9806365966796875
    },
    {
      "query": "What happens if the mode is activated on the fire-recall floor?",
      "predicted_response": "the elevator will have an alternate floor to recall to",
      "method": "exact-match",
      "actual_response": "the elevator will have an alternate floor to recall to",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8699985705316067e-05,
        "tree_retrieval": 0.08541266398970038,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2586275420617312,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0705066919326782
    },
    {
      "query": "What does the Fermat primality test depend upon?",
      "predicted_response": "np\u2261n (mod p)",
      "method": "exact-match",
      "actual_response": "np\u2261n (mod p)",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.7699978090822697e-05,
        "tree_retrieval": 0.0856702650198713,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23981250007636845,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9960482120513916
    },
    {
      "query": "What year was the PlayStation 3 released?",
      "predicted_response": "2006",
      "method": "exact-match",
      "actual_response": "2006",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.7999980375170708e-05,
        "tree_retrieval": 0.08328735991381109,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.25346591603010893,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8033151626586914
    },
    {
      "query": "Who is the current captian of the cricket team?",
      "predicted_response": "Rakep Patel",
      "method": "exact-match",
      "actual_response": "Rakep Patel",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.040092997252941e-05,
        "tree_retrieval": 0.08698096696753055,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2458398339804262,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9145548343658447
    },
    {
      "query": "Who helped with the Free Elections?",
      "predicted_response": "UN Office of Electoral Affairs",
      "method": "exact-match",
      "actual_response": "UN Office of Electoral Affairs",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9399991035461426e-05,
        "tree_retrieval": 0.08654006593860686,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.24716970790177584,
      "bert_score": 0.9999996423721313,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.051126480102539
    },
    {
      "query": "Where is the Fylde coast?",
      "predicted_response": "Blackpool Urban Area",
      "method": "exact-match",
      "actual_response": "Blackpool Urban Area",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1400006264448166e-05,
        "tree_retrieval": 0.08583746501244605,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.237637875135988,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0105761289596558
    },
    {
      "query": "Where is the Nea Moni Monastery located?",
      "predicted_response": "Chios",
      "method": "exact-match",
      "actual_response": "Chios",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.10999234393239e-05,
        "tree_retrieval": 0.08494546299334615,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2362074579577893,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8480039238929749
    },
    {
      "query": "What was the first carrier-launched airstrike?",
      "predicted_response": "the Tondern Raid in July 1918",
      "method": "exact-match",
      "actual_response": "the Tondern Raid in July 1918",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.5600078515708447e-05,
        "tree_retrieval": 0.08296755899209529,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2343874159269035,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0573056936264038
    },
    {
      "query": "What is the county's payroll?",
      "predicted_response": "greater than $733 million.",
      "method": "exact-match",
      "actual_response": "greater than $733 million.",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.920010592788458e-05,
        "tree_retrieval": 0.08665546600241214,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.3022429998964071,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0997694730758667
    },
    {
      "query": "What do forces have with regard to additive quantities?",
      "predicted_response": "magnitude and direction",
      "method": "exact-match",
      "actual_response": "magnitude and direction",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.729997504502535e-05,
        "tree_retrieval": 0.09237629501149058,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.29266120912507176,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0465612411499023
    },
    {
      "query": "What percent decrease did audio CD sales experience?",
      "predicted_response": "50%",
      "method": "exact-match",
      "actual_response": "50%",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.4999953135848045e-05,
        "tree_retrieval": 0.08524028491228819,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23962058406323195,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9902071952819824
    },
    {
      "query": "Who was influenced by Western European and Islamic tendencies?",
      "predicted_response": "Greek masters working in Sicily",
      "method": "exact-match",
      "actual_response": "Greek masters working in Sicily",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.090000245720148e-05,
        "tree_retrieval": 0.08563128695823252,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23841437511146069,
      "bert_score": 0.9999996423721313,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.057360053062439
    },
    {
      "query": "Who said in 2012 that the fight would change from military to law enforcement?",
      "predicted_response": "Jeh Johnson",
      "method": "exact-match",
      "actual_response": "Jeh Johnson",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8399983420968056e-05,
        "tree_retrieval": 0.08591328701004386,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.31139249983243644,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9000398516654968
    },
    {
      "query": "Which company made Spectre?",
      "predicted_response": "Eon Productions",
      "method": "exact-match",
      "actual_response": "Eon Productions",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8799986466765404e-05,
        "tree_retrieval": 0.08623748796526343,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.29460783395916224,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8703005313873291
    },
    {
      "query": "What sports activity is featured in The Times on Mondays?",
      "predicted_response": "football",
      "method": "exact-match",
      "actual_response": "football",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.589996438473463e-05,
        "tree_retrieval": 0.08264257700648159,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23501891596242785,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8423523902893066
    },
    {
      "query": "What area differs from other areas in the United Kingdom regarding education?",
      "predicted_response": "Wales",
      "method": "exact-match",
      "actual_response": "Wales",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8999987989664078e-05,
        "tree_retrieval": 0.0853077860083431,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2387259160168469,
      "bert_score": 0.9999992251396179,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8903079032897949
    },
    {
      "query": "What type of paper is The Siasat Daily?",
      "predicted_response": "major Urdu papers",
      "method": "exact-match",
      "actual_response": "major Urdu papers",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.1200045011937618e-05,
        "tree_retrieval": 0.08465048298239708,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.30917712510563433,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0010067224502563
    },
    {
      "query": "Which Soviet countries did the RSFSR border on the west?",
      "predicted_response": "the Ukrainian, Belarusian, Estonian, Latvian and Lithuanian SSRs",
      "method": "exact-match",
      "actual_response": "the Ukrainian, Belarusian, Estonian, Latvian and Lithuanian SSRs",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8999987989664078e-05,
        "tree_retrieval": 0.0853284850018099,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.3087149579077959,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0337799787521362
    },
    {
      "query": "This type of problem happens in any organization where the interests of the people who financially support it conflicts with what?",
      "predicted_response": "the primary purpose of the institution",
      "method": "exact-match",
      "actual_response": "the primary purpose of the institution",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.4399952962994576e-05,
        "tree_retrieval": 0.08576468704268336,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23831958300434053,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0828161239624023
    },
    {
      "query": "What is the Windows 8 Pro price?",
      "predicted_response": "$199.99",
      "method": "exact-match",
      "actual_response": "$199.99",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.2100011594593525e-05,
        "tree_retrieval": 0.08574878703802824,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.34815095900557935,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0298289060592651
    },
    {
      "query": "What online service did the National Archives decide to use to showcase its photographic holdings?",
      "predicted_response": "Flickr",
      "method": "exact-match",
      "actual_response": "Flickr",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9400107450783253e-05,
        "tree_retrieval": 0.08537258603610098,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2377160838805139,
      "bert_score": 0.9999997019767761,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8906532526016235
    },
    {
      "query": "What is a broad, modern working definition of a gene?",
      "predicted_response": "any discrete locus of heritable, genomic sequence which affect an organism's traits by being expressed as a functional product",
      "method": "exact-match",
      "actual_response": "any discrete locus of heritable, genomic sequence which affect an organism's traits by being expressed as a functional product",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.2000051103532314e-05,
        "tree_retrieval": 0.08663638995494694,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.26279904204420745,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0265333652496338
    },
    {
      "query": "Why is tort law hard to standardize?",
      "predicted_response": "immense size and diversity",
      "method": "exact-match",
      "actual_response": "immense size and diversity",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9499991796910763e-05,
        "tree_retrieval": 0.08709399099461734,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23969325004145503,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0751700401306152
    },
    {
      "query": "What had a hold over social life in the Ottoman Empire as well as other cultures?",
      "predicted_response": "religion",
      "method": "exact-match",
      "actual_response": "religion",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9499991796910763e-05,
        "tree_retrieval": 0.08300397801212966,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.24492054083384573,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.848621129989624
    },
    {
      "query": "Who does the evaluations for drugs in the United Kingdom?",
      "predicted_response": "European Medicines Agency",
      "method": "exact-match",
      "actual_response": "European Medicines Agency",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.219993621110916e-05,
        "tree_retrieval": 0.08712779101915658,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.24713174998760223,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0507718324661255
    },
    {
      "query": "In what year was the God's House Tower built?",
      "predicted_response": "1417",
      "method": "exact-match",
      "actual_response": "1417",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.729997504502535e-05,
        "tree_retrieval": 0.08326867897994816,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2349075418896973,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8043615818023682
    },
    {
      "query": "What is a PoP?",
      "predicted_response": "point of presence",
      "method": "exact-match",
      "actual_response": "point of presence",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9699993319809437e-05,
        "tree_retrieval": 0.0844026820268482,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.30289991688914597,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0720758438110352
    },
    {
      "query": "What tree leaves did Androsthenes describe?",
      "predicted_response": "tamarind",
      "method": "exact-match",
      "actual_response": "tamarind",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.489995677024126e-05,
        "tree_retrieval": 0.08803829504176974,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.29005691688507795,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8776722550392151
    },
    {
      "query": "Where is the North Hills Shopping center?",
      "predicted_response": "Midtown Raleigh",
      "method": "exact-match",
      "actual_response": "Midtown Raleigh",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.810091245919466e-05,
        "tree_retrieval": 0.08287667704280466,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23560033296234906,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0296317338943481
    },
    {
      "query": "What does law enforcement in some countries use to profile suspects?",
      "predicted_response": "race",
      "method": "exact-match",
      "actual_response": "race",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.989999484270811e-05,
        "tree_retrieval": 0.08454438298940659,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2585348749998957,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8122368454933167
    },
    {
      "query": "What is it easier to do regarding God?",
      "predicted_response": "state what God is not",
      "method": "exact-match",
      "actual_response": "state what God is not",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 4.840001929551363e-05,
        "tree_retrieval": 0.08426208200398833,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2375793750397861,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0840314626693726
    },
    {
      "query": " What is the second most populous of Switzerland's cantons?",
      "predicted_response": "Canton of Bern",
      "method": "exact-match",
      "actual_response": "Canton of Bern",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9499991796910763e-05,
        "tree_retrieval": 0.0847330839606002,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2393475421704352,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.992042064666748
    },
    {
      "query": "When did the Reconstruction Era end?",
      "predicted_response": "1877",
      "method": "exact-match",
      "actual_response": "1877",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8399983420968056e-05,
        "tree_retrieval": 0.08374258002731949,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.29468183289282024,
      "bert_score": 0.9999998211860657,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8476759195327759
    },
    {
      "query": "808s & Heartbreak was released by what company? ",
      "predicted_response": "Island Def Jam",
      "method": "exact-match",
      "actual_response": "Island Def Jam",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.110003985464573e-05,
        "tree_retrieval": 0.08391698088962585,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.3079977079760283,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9238510727882385
    },
    {
      "query": "What type of stimuli causes pain?",
      "predicted_response": "intense or damaging",
      "method": "exact-match",
      "actual_response": "intense or damaging",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.120000474154949e-05,
        "tree_retrieval": 0.08354567899368703,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23643583385273814,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0752239227294922
    },
    {
      "query": "When did season 14 premiere?",
      "predicted_response": "January 7, 2015",
      "method": "exact-match",
      "actual_response": "January 7, 2015",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9199989512562752e-05,
        "tree_retrieval": 0.08628688903991133,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2398346250411123,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.1207845211029053
    },
    {
      "query": "Maududi was trained as a lawyer, but chose what professional for himself instead?",
      "predicted_response": "journalism",
      "method": "exact-match",
      "actual_response": "journalism",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9400107450783253e-05,
        "tree_retrieval": 0.0891715990146622,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.29369383305311203,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8349429965019226
    },
    {
      "query": "Who is the professional head of the British Armed Forces?",
      "predicted_response": "Chief of the Defence Staff",
      "method": "exact-match",
      "actual_response": "Chief of the Defence Staff",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.929999027401209e-05,
        "tree_retrieval": 0.0838781800121069,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2378778331913054,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0919629335403442
    },
    {
      "query": "War was started with the Ottomans when?",
      "predicted_response": "17 March 1821",
      "method": "exact-match",
      "actual_response": "17 March 1821",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.929999027401209e-05,
        "tree_retrieval": 0.08498780697118491,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23841658304445446,
      "bert_score": 1.0000005960464478,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0445047616958618
    },
    {
      "query": "What was published the same years?",
      "predicted_response": "Annus Mirabilis Papers",
      "method": "exact-match",
      "actual_response": "Annus Mirabilis Papers",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.450007013976574e-05,
        "tree_retrieval": 0.08661775500513613,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2921670419164002,
      "bert_score": 1.0000004768371582,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9631952047348022
    },
    {
      "query": "What can tamers do in order to give their partners advantages?",
      "predicted_response": "slide game cards through their \"Digivices",
      "method": "exact-match",
      "actual_response": "slide game cards through their \"Digivices",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.889998722821474e-05,
        "tree_retrieval": 0.08392114494927227,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23710945807397366,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0654115676879883
    },
    {
      "query": "What does Stephen Jay Gould call philosophy that deals in the supernatural?",
      "predicted_response": "non-overlapping magisteria\" (NOMA)",
      "method": "exact-match",
      "actual_response": "non-overlapping magisteria\" (NOMA)",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.829998265951872e-05,
        "tree_retrieval": 0.08498744899407029,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23844358301721513,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.036368727684021
    },
    {
      "query": "The path was important for the expansion of which road?",
      "predicted_response": "El Camino Real de Tierra Adentro",
      "method": "exact-match",
      "actual_response": "El Camino Real de Tierra Adentro",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8699985705316067e-05,
        "tree_retrieval": 0.08414134499616921,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2376620420254767,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9958230257034302
    },
    {
      "query": "What did Burke think a social hierarchy should be based on?",
      "predicted_response": "property",
      "method": "exact-match",
      "actual_response": "property",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9799994081258774e-05,
        "tree_retrieval": 0.08300574100576341,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23739424999803305,
      "bert_score": 1.0000003576278687,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9001156091690063
    },
    {
      "query": "What is the term given to 122nd Street by Wizard in Taxi Driver indicating the area is majority black?",
      "predicted_response": "\"Mau Mau Land\"",
      "method": "exact-match",
      "actual_response": "\"Mau Mau Land\"",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.5999965146183968e-05,
        "tree_retrieval": 0.08388354408089072,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2388864578679204,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.011643886566162
    },
    {
      "query": "What were the only proteins necessary to the circadian timekeeper experiment?",
      "predicted_response": "KaiA, KaiB, KaiC",
      "method": "exact-match",
      "actual_response": "KaiA, KaiB, KaiC",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8399983420968056e-05,
        "tree_retrieval": 0.08507554908283055,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.3551087090745568,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9800236821174622
    },
    {
      "query": "How many delegates passed the motion?",
      "predicted_response": "129",
      "method": "exact-match",
      "actual_response": "129",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8399983420968056e-05,
        "tree_retrieval": 0.08667645591776818,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2649019160307944,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8013512492179871
    },
    {
      "query": "How are incomes distributed in Sweden?",
      "predicted_response": "more equally",
      "method": "exact-match",
      "actual_response": "more equally",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9699993319809437e-05,
        "tree_retrieval": 0.0845981469610706,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.3185413330793381,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9076771140098572
    },
    {
      "query": "What group declared independence as Asawad?",
      "predicted_response": "MNLA",
      "method": "exact-match",
      "actual_response": "MNLA",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0499999411404133e-05,
        "tree_retrieval": 0.08557185099925846,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.3913463749922812,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8234075307846069
    },
    {
      "query": "How high is Granite Peak?",
      "predicted_response": "12,799 feet",
      "method": "exact-match",
      "actual_response": "12,799 feet",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8999987989664078e-05,
        "tree_retrieval": 0.08707685803528875,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2391784170176834,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0630075931549072
    },
    {
      "query": "What was the name given to the land that North Carolina transferred to the federal government in 1790?",
      "predicted_response": "Southwest Territory",
      "method": "exact-match",
      "actual_response": "Southwest Territory",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.329994458705187e-05,
        "tree_retrieval": 0.08443214604631066,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23655975004658103,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.021000623703003
    },
    {
      "query": "How many planes did the United States have in the Battle of Midway?",
      "predicted_response": "348",
      "method": "exact-match",
      "actual_response": "348",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8099981136620045e-05,
        "tree_retrieval": 0.08540445100516081,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2370435418561101,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8334561586380005
    },
    {
      "query": "What is another name for the Eastern Roman Empire?",
      "predicted_response": "Byzantine Empire",
      "method": "exact-match",
      "actual_response": "Byzantine Empire",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0600931495428085e-05,
        "tree_retrieval": 0.08513864898122847,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.6652537919580936,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9485074281692505
    },
    {
      "query": "What pontifax maximus favored the Catholic church? ",
      "predicted_response": "Constantine I",
      "method": "exact-match",
      "actual_response": "Constantine I",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0099996365606785e-05,
        "tree_retrieval": 0.08706275699660182,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.28583949990570545,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8883588910102844
    },
    {
      "query": "What is a brief description of Calvinism?",
      "predicted_response": "the sovereignty or rule of God in all things",
      "method": "exact-match",
      "actual_response": "the sovereignty or rule of God in all things",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.95999925583601e-05,
        "tree_retrieval": 0.08548195101320744,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2979765001218766,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.083367943763733
    },
    {
      "query": "A non-deterministic Turing machine has the ability to capture what facet of useful analysis?",
      "predicted_response": "mathematical models",
      "method": "exact-match",
      "actual_response": "mathematical models",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9499991796910763e-05,
        "tree_retrieval": 0.08673555590212345,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.27863833401352167,
      "bert_score": 0.9999996423721313,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9497608542442322
    },
    {
      "query": "The values of the bourgeois public sphere included holding reason to the supreme, considering everything open to criticism, and the opposition of what?",
      "predicted_response": "secrecy of all sorts",
      "method": "exact-match",
      "actual_response": "secrecy of all sorts",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.329994458705187e-05,
        "tree_retrieval": 0.08435584604740143,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23545445804484189,
      "bert_score": 0.9999996423721313,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0873037576675415
    },
    {
      "query": "What provided an incentive to western empires to colonize Africa?",
      "predicted_response": "blank spaces on contemporary maps",
      "method": "exact-match",
      "actual_response": "blank spaces on contemporary maps",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.5699962861835957e-05,
        "tree_retrieval": 0.08507844898849726,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2361518330872059,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0563441514968872
    },
    {
      "query": "What year did the Blackstone Group express interest in acquiring Dell?",
      "predicted_response": "2013",
      "method": "exact-match",
      "actual_response": "2013",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9699993319809437e-05,
        "tree_retrieval": 0.08663475594948977,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.3183774168137461,
      "bert_score": 1.0000009536743164,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8252943754196167
    },
    {
      "query": "What was Kerry's role in the Yale Political Union as a sophomore?",
      "predicted_response": "Chairman of the Liberal Party",
      "method": "exact-match",
      "actual_response": "Chairman of the Liberal Party",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8699985705316067e-05,
        "tree_retrieval": 0.08491224807221442,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23600608319975436,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0633039474487305
    },
    {
      "query": "What do bergschrunds resemble?",
      "predicted_response": "crevasses",
      "method": "exact-match",
      "actual_response": "crevasses",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.519995905458927e-05,
        "tree_retrieval": 0.08412754500750452,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.23602570896036923,
      "bert_score": 1.0000004768371582,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9252892136573792
    },
    {
      "query": "To whom did Luther send a letter containing his 95 Theses?",
      "predicted_response": "Archbishop Albrecht",
      "method": "exact-match",
      "actual_response": "Archbishop Albrecht",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.2900053560733795e-05,
        "tree_retrieval": 0.08760275901295245,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.31110029201954603,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9447121024131775
    },
    {
      "query": "In what year did Lobund at Notre Dame become an Institute?",
      "predicted_response": "1950",
      "method": "exact-match",
      "actual_response": "1950",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8399983420968056e-05,
        "tree_retrieval": 0.08539995003957301,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.657716624904424,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.7846388816833496
    },
    {
      "query": "What percentage of the European population consisted of monks?",
      "predicted_response": "less than one per cent",
      "method": "exact-match",
      "actual_response": "less than one per cent",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0399998649954796e-05,
        "tree_retrieval": 0.08551065099891275,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.3318032920360565,
      "bert_score": 0.9999997019767761,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0894526243209839
    },
    {
      "query": "What advantage would taking St. John's have provided for the French?",
      "predicted_response": "the expedition would have strengthened France's hand at the negotiating table",
      "method": "exact-match",
      "actual_response": "the expedition would have strengthened France's hand at the negotiating table",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8999987989664078e-05,
        "tree_retrieval": 0.08703817299101502,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.2650698749348521,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0396236181259155
    },
    {
      "query": "Where are most of these companies located in an airport?",
      "predicted_response": "within the departure areas",
      "method": "exact-match",
      "actual_response": "within the departure areas",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.929999027401209e-05,
        "tree_retrieval": 0.08454006898682564,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 0.31618054187856615,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0583711862564087
    },
    {
      "query": "What is the earliest year the term \"redhead\" was used?",
      "predicted_response": "1510",
      "method": "exact-match",
      "actual_response": "1510",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.130000550299883e-05,
        "tree_retrieval": 5.096007857006043,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 5.305381833110005,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.7835979461669922
    },
    {
      "query": "Which nation did Kerry travel to during her student years?",
      "predicted_response": "Switzerland",
      "method": "exact-match",
      "actual_response": "Switzerland",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.010003224015236e-05,
        "tree_retrieval": 4.3624655469320714,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.593128625070676,
      "bert_score": 0.999999463558197,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9241113662719727
    },
    {
      "query": "Where in Greenland do glaciers advance 20-30 meters daily?",
      "predicted_response": "Jakobshavn Isbr\u00e6",
      "method": "exact-match",
      "actual_response": "Jakobshavn Isbr\u00e6",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8699985705316067e-05,
        "tree_retrieval": 4.713855237001553,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.865667999954894,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9309401512145996
    },
    {
      "query": "What is the purpose of these statutes?",
      "predicted_response": "freedom of speech",
      "method": "exact-match",
      "actual_response": "freedom of speech",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.100003909319639e-05,
        "tree_retrieval": 4.353992254007608,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.519029000075534,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0812143087387085
    },
    {
      "query": "Which places on Egypt's northern coast are popular for recreational tourism?",
      "predicted_response": "Dahab, Ras Sidr, Marsa Alam, Safaga",
      "method": "exact-match",
      "actual_response": "Dahab, Ras Sidr, Marsa Alam, Safaga",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9699993319809437e-05,
        "tree_retrieval": 4.388520219945349,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.611053084023297,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9877368211746216
    },
    {
      "query": "How did Whitehead suggest reality should be perceived?",
      "predicted_response": "experiential",
      "method": "exact-match",
      "actual_response": "experiential",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1400006264448166e-05,
        "tree_retrieval": 4.361675542080775,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.514792916132137,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0307166576385498
    },
    {
      "query": "Which organization represents all cable companies in Washington?",
      "predicted_response": "The National Cable & Telecommunications Association",
      "method": "exact-match",
      "actual_response": "The National Cable & Telecommunications Association",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.15000070258975e-05,
        "tree_retrieval": 4.617144207004458,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.867530666058883,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0473757982254028
    },
    {
      "query": "Who stepped down from their role in 1839?",
      "predicted_response": "Melbourne",
      "method": "exact-match",
      "actual_response": "Melbourne",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9799994081258774e-05,
        "tree_retrieval": 4.705322587047704,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.866827625082806,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8353593349456787
    },
    {
      "query": "What can be accomplished without constructing tall structures or eliminating shared spaces?",
      "predicted_response": "their approach to building design",
      "method": "exact-match",
      "actual_response": "high density",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0199997127056122e-05,
        "tree_retrieval": 4.481498935027048,
        "debate": 61.019691328983754,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.633486874867231,
      "bert_score": 0.8316892385482788,
      "f1_score": 0,
      "rouge_score": 0.0,
      "bleurt_score": -1.0811744928359985
    },
    {
      "query": "What description was partially given to the minority leader?",
      "predicted_response": "Minority leader in Westeurope's parliamentary systems is a key figure, embodying leadership and effective opposition representation. Originating during the early 20th century to structure smaller factions for equitable participation, this role improves legislative dialogue beyond mere numerical strength. The minority leader serves as the party's spokesperson, articulating its policies during negotiations towards societal benefits through policy-making, significantly contributing to maintaining a vibrant political ecosystem conducive to democratic discourse.",
      "method": "debate",
      "actual_response": "He is spokesman for his party and enunciates its policies.",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.270106390118599e-05,
        "tree_retrieval": 4.731399670010433,
        "debate": 104.88014969206415,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 109.84999016695656,
      "bert_score": 0.8458631038665771,
      "f1_score": 0.13698630136986303,
      "rouge_score": 0.1234567901234568,
      "bleurt_score": -0.20565913617610931
    },
    {
      "query": "What position did France take as Prussia aimed to integrate various German kingdoms?",
      "predicted_response": "strongly opposed to any further alliance of German states",
      "method": "exact-match",
      "actual_response": "strongly opposed to any further alliance of German states",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.260001540184021e-05,
        "tree_retrieval": 4.814957052934915,
        "debate": 104.88014969206415,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.970902375178412,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0470067262649536
    },
    {
      "query": "In which location was the Indo-Greek Kingdom situated?",
      "predicted_response": "South Asia",
      "method": "exact-match",
      "actual_response": "South Asia",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.070000093430281e-05,
        "tree_retrieval": 4.393369197030552,
        "debate": 104.88014969206415,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.64242879091762,
      "bert_score": 0.9999995231628418,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9841454029083252
    },
    {
      "query": "What contributed to improved fuse setting?",
      "predicted_response": "range measurement",
      "method": "exact-match",
      "actual_response": "range measurement",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1800009310245514e-05,
        "tree_retrieval": 4.365782322012819,
        "debate": 104.88014969206415,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.581999083980918,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0036875009536743
    },
    {
      "query": "Which technique is employed to evaluate software performance under a particular load?",
      "predicted_response": "Load testing",
      "method": "exact-match",
      "actual_response": "Load testing",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.140004213899374e-05,
        "tree_retrieval": 4.398848938988522,
        "debate": 104.88014969206415,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.614497167058289,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9525935649871826
    },
    {
      "query": "What is the global volume of growing stock forest in cubic meters?",
      "predicted_response": "434 billion",
      "method": "exact-match",
      "actual_response": "434 billion",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.4999953135848045e-05,
        "tree_retrieval": 4.704870217014104,
        "debate": 104.88014969206415,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.857191290939227,
      "bert_score": 0.9999998211860657,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9508146047592163
    },
    {
      "query": "What was the original Quantum theory?",
      "predicted_response": "Quantum theory is a collection of early scientific findings that aimed to explain phenomena observable only at microscopic scales. These theories were not fully developed or self-consistent compared to modern quantum mechanics standards. Ada Lovelace's work with Charles Babbage on algorithms for his Analytical Engine demonstrated early concepts similar to programming as we know it today. Her understanding of iterative processes and conditional branching showed that computers had potential applications beyond pure mathematics into creative endeavors like music composition. This forward-thinking approach underscores Lovelace's lasting influence on modern computing thought processes, inspiring contemporary programming philosophies and serving as an exemplary model for computational innovation throughout history.",
      "method": "debate",
      "actual_response": "a collection of results which predate modern quantum mechanics, but were never complete or self-consistent.",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.189993392676115e-05,
        "tree_retrieval": 4.40551953506656,
        "debate": 211.86735572991893,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 216.43794145807624,
      "bert_score": 0.8648634552955627,
      "f1_score": 0.13559322033898308,
      "rouge_score": 0.11111111111111112,
      "bleurt_score": -0.12506933510303497
    },
    {
      "query": "Who currently holds the position of administrator on Norfolk Island?",
      "predicted_response": "Gary Hardgrave",
      "method": "exact-match",
      "actual_response": "Gary Hardgrave",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1400006264448166e-05,
        "tree_retrieval": 4.851942247943953,
        "debate": 211.86735572991893,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 5.004326708847657,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9021804928779602
    },
    {
      "query": "Which yearly sports event includes the Wanamaker Mile?",
      "predicted_response": "Millrose Games",
      "method": "exact-match",
      "actual_response": "Millrose Games",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9199989512562752e-05,
        "tree_retrieval": 4.345433979993686,
        "debate": 211.86735572991893,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.543518291087821,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8905800580978394
    },
    {
      "query": "Which significant battle took place in 731?",
      "predicted_response": "Battle of the Defile",
      "method": "exact-match",
      "actual_response": "Battle of the Defile",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.2999942302703857e-05,
        "tree_retrieval": 4.437387919984758,
        "debate": 211.86735572991893,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.609464292181656,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0492271184921265
    },
    {
      "query": "Which device appeared ideal for Link's arrow shooting skill?",
      "predicted_response": "Wii Remote",
      "method": "exact-match",
      "actual_response": "Wii Remote",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.070003680884838e-05,
        "tree_retrieval": 4.3968986991094425,
        "debate": 211.86735572991893,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.660419917199761,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9552720189094543
    },
    {
      "query": "In addition to Reims, which city in France is home to a famous Gothic cathedral?",
      "predicted_response": "Chartres",
      "method": "exact-match",
      "actual_response": "Chartres",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.2300944440066814e-05,
        "tree_retrieval": 4.52506606397219,
        "debate": 211.86735572991893,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.690510458080098,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.915695071220398
    },
    {
      "query": "Which state contributed land to Washington, D.C., but later had it returned?",
      "predicted_response": "Virginia",
      "method": "exact-match",
      "actual_response": "Virginia",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9799994081258774e-05,
        "tree_retrieval": 4.441963708028197,
        "debate": 211.86735572991893,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.594844083068892,
      "bert_score": 0.9999990463256836,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8640045523643494
    },
    {
      "query": "Why did Sting and other artists call off their planned shows in Kazakhstan?",
      "predicted_response": "human rights concerns",
      "method": "exact-match",
      "actual_response": "human rights concerns",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0099996365606785e-05,
        "tree_retrieval": 4.687850542948581,
        "debate": 211.86735572991893,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.887583750067279,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0685172080993652
    },
    {
      "query": "When did Britain complete repayment of the US loan?",
      "predicted_response": "2006",
      "method": "exact-match",
      "actual_response": "2006",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.5700079277157784e-05,
        "tree_retrieval": 4.449436007998884,
        "debate": 211.86735572991893,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.601381791988388,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8033151626586914
    },
    {
      "query": "What information should users know when encoding music to prevent testing each track individually?",
      "predicted_response": "quality setting",
      "method": "exact-match",
      "actual_response": "quality setting",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9699993319809437e-05,
        "tree_retrieval": 4.439407382975332,
        "debate": 211.86735572991893,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.685473707970232,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0486217737197876
    },
    {
      "query": "What is the full form of CRA?",
      "predicted_response": "Community Reinvestment Act",
      "method": "exact-match",
      "actual_response": "Community Reinvestment Act",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0800001695752144e-05,
        "tree_retrieval": 4.428915763972327,
        "debate": 211.86735572991893,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.587001417065039,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0376451015472412
    },
    {
      "query": "Which annelid species differ significantly from the rest?",
      "predicted_response": "Annelida contains leeches and their relatives in a distinct subgroup because of their non-segmental characteristics in both extremities. Unlike most other segmented annelids that consistently display segmentation throughout from head to tail, these species show structural variations at the frontmost (head) end and rearmost sections nearing the 'tail', which sets them apart within the diversity of annelids.",
      "method": "debate",
      "actual_response": "leeches and their closest relatives",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.060000017285347e-05,
        "tree_retrieval": 4.421695664059371,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 88.69854504195973,
      "bert_score": 0.8203875422477722,
      "f1_score": 0.13793103448275862,
      "rouge_score": 0.12698412698412698,
      "bleurt_score": -0.23569883406162262
    },
    {
      "query": "Who was the owner of the building at 29 East 32nd Street from 1890 to 1917?",
      "predicted_response": "Grolier Club",
      "method": "exact-match",
      "actual_response": "Grolier Club",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0199997127056122e-05,
        "tree_retrieval": 4.923251742962748,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 5.191881624981761,
      "bert_score": 1.0000005960464478,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9219409227371216
    },
    {
      "query": "What additions can Parliament make to the citizen-proposed amendment?",
      "predicted_response": "a counter-proposal",
      "method": "exact-match",
      "actual_response": "a counter-proposal",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.250001464039087e-05,
        "tree_retrieval": 4.549846905982122,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.721622166922316,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0997300148010254
    },
    {
      "query": "What purposes have various technologies been developed to serve, as suggested by the phrase \"There's an app for that\"?",
      "predicted_response": "assist hunters",
      "method": "exact-match",
      "actual_response": "assist hunters",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0800001695752144e-05,
        "tree_retrieval": 4.762322305003181,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.952317333081737,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.1005691289901733
    },
    {
      "query": "How many cities in India have been chosen for smart city development?",
      "predicted_response": "hundred",
      "method": "exact-match",
      "actual_response": "hundred",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.070000093430281e-05,
        "tree_retrieval": 4.629754635039717,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.799749917117879,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9251022338867188
    },
    {
      "query": "How is Liaoning categorized?",
      "predicted_response": "a training ship",
      "method": "exact-match",
      "actual_response": "a training ship",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.459995448589325e-05,
        "tree_retrieval": 4.555298766004853,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.767123542027548,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0531569719314575
    },
    {
      "query": "How many proteins typically make up a flagellum?",
      "predicted_response": "20 proteins",
      "method": "exact-match",
      "actual_response": "20 proteins",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.070000093430281e-05,
        "tree_retrieval": 4.618472489062697,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.794247624929994,
      "bert_score": 1.0000005960464478,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9217514991760254
    },
    {
      "query": "What are Universities of Technology called in French-speaking regions?",
      "predicted_response": "Instituts de technologie",
      "method": "exact-match",
      "actual_response": "Instituts de technologie",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.070000093430281e-05,
        "tree_retrieval": 4.552235359093174,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.794474791968241,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.006797432899475
    },
    {
      "query": "Who among Alexander's commanders was the first to reach Bahrain?",
      "predicted_response": "Nearchus",
      "method": "exact-match",
      "actual_response": "Nearchus",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.100093454122543e-05,
        "tree_retrieval": 4.503289113054052,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.709832750027999,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8017319440841675
    },
    {
      "query": "Which under-construction building will exceed the height of Comcast Center?",
      "predicted_response": "Comcast Innovation and Technology Center",
      "method": "exact-match",
      "actual_response": "Comcast Innovation and Technology Center",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.929999027401209e-05,
        "tree_retrieval": 4.473885721992701,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.640808666823432,
      "bert_score": 0.9999998211860657,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9811744689941406
    },
    {
      "query": "How do the actions of the God in Dvaita differ from those in Advaita?",
      "predicted_response": "takes on a personal role",
      "method": "exact-match",
      "actual_response": "takes on a personal role",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9799994081258774e-05,
        "tree_retrieval": 4.699617903097533,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.851751749869436,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0939216613769531
    },
    {
      "query": "Who became the Prime Minister in 1999?",
      "predicted_response": "Ehud Barak",
      "method": "exact-match",
      "actual_response": "Ehud Barak",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.100003909319639e-05,
        "tree_retrieval": 4.393888494931161,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.5934415000956506,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9082248210906982
    },
    {
      "query": "Which UK company did Microsoft collaborate with to introduce IPTV to the 360?",
      "predicted_response": "BT",
      "method": "exact-match",
      "actual_response": "BT",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.060000017285347e-05,
        "tree_retrieval": 4.375740137998946,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.562919749878347,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8395583629608154
    },
    {
      "query": "When did someone file a Title IX complaint against Yale?",
      "predicted_response": "March 2011",
      "method": "exact-match",
      "actual_response": "March 2011",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9199989512562752e-05,
        "tree_retrieval": 4.672861301922239,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.8260787080507725,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9811782836914062
    },
    {
      "query": "What type of entity is MundoFox?",
      "predicted_response": "Spanish-language television networks",
      "method": "exact-match",
      "actual_response": "Spanish-language television networks",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0099996365606785e-05,
        "tree_retrieval": 4.6091305209556594,
        "debate": 84.124107902986,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.77727979188785,
      "bert_score": 0.9999998211860657,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0543640851974487
    },
    {
      "query": "What is next to the abbey?",
      "predicted_response": "The proposed work for the abbey in 2009 aimed to enhance tourist experience while preserving original essence and integrity. This may include restorative architecture efforts, museum facility improvements, local history exploration, cultural events, educational programs, and potential collaborations with other historic landmarks like The Palace of Westminster to celebrate England\u2019s architectural heritage.",
      "method": "debate",
      "actual_response": "Palace of Westminster",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8399983420968056e-05,
        "tree_retrieval": 4.611010696040466,
        "debate": 180.43631395301782,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 185.2005759170279,
      "bert_score": 0.8304817080497742,
      "f1_score": 0.11538461538461538,
      "rouge_score": 0.10714285714285715,
      "bleurt_score": -0.38823553919792175
    },
    {
      "query": "Who manufactured the Twin Famicom and the 19SC111 TV?",
      "predicted_response": "Sharp Corporation",
      "method": "exact-match",
      "actual_response": "Sharp Corporation",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9799994081258774e-05,
        "tree_retrieval": 4.841391082969494,
        "debate": 180.43631395301782,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.993574999971315,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9227376580238342
    },
    {
      "query": "What is an agreement made between multiple nations called?",
      "predicted_response": "A multilateral treaty is an agreement between multiple nations regarding cooperation on matters of mutual interest and benefit, covering areas such as trade, defense, environmental protection, and human rights under international law. It fosters international relations by formalizing commitments.",
      "method": "debate",
      "actual_response": "A multilateral treaty",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.95999925583601e-05,
        "tree_retrieval": 4.8495788250584155,
        "debate": 70.56432171002962,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 75.64847987494431,
      "bert_score": 0.8608632683753967,
      "f1_score": 0.10256410256410257,
      "rouge_score": 0.14285714285714288,
      "bleurt_score": 0.05594785511493683
    },
    {
      "query": "In what year did the Gallipoli Campaign occur?",
      "predicted_response": "1915",
      "method": "exact-match",
      "actual_response": "1915",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9799994081258774e-05,
        "tree_retrieval": 4.873238519066945,
        "debate": 70.56432171002962,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 5.102546124951914,
      "bert_score": 1.0000003576278687,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8537719249725342
    },
    {
      "query": "What is Alsace's historical flag called?",
      "predicted_response": "Rot-un-Wiss",
      "method": "exact-match",
      "actual_response": "Rot-un-Wiss",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1800009310245514e-05,
        "tree_retrieval": 4.500970473047346,
        "debate": 70.56432171002962,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.689288291148841,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0118333101272583
    },
    {
      "query": "What is the name of Israel's legislative body?",
      "predicted_response": "the Knesset",
      "method": "exact-match",
      "actual_response": "the Knesset",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.120000474154949e-05,
        "tree_retrieval": 4.571399950073101,
        "debate": 70.56432171002962,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.739552916958928,
      "bert_score": 0.9999998211860657,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9735682010650635
    },
    {
      "query": "What were the nomadic tribes called that hunted bison?",
      "predicted_response": "Jornado",
      "method": "exact-match",
      "actual_response": "Jornado",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.41999514400959e-05,
        "tree_retrieval": 4.635107004083693,
        "debate": 70.56432171002962,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.788583334069699,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8818092942237854
    },
    {
      "query": "In which scientific discipline did Wohler make a discovery?",
      "predicted_response": "organic chemistry",
      "method": "exact-match",
      "actual_response": "organic chemistry",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0399998649954796e-05,
        "tree_retrieval": 4.544777805916965,
        "debate": 70.56432171002962,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.698068000143394,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9222978949546814
    },
    {
      "query": "What is Oklahoma's ranking in crude oil reserves compared to other states?",
      "predicted_response": "fifth",
      "method": "exact-match",
      "actual_response": "fifth",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.28009482473135e-05,
        "tree_retrieval": 4.481794556952082,
        "debate": 70.56432171002962,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.634483624948189,
      "bert_score": 0.9999997019767761,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9879858493804932
    },
    {
      "query": "During which era did Queen Victoria rule?",
      "predicted_response": "The Victorian Era spanned from January 1st, 1837 to just before a decade into the new century following Queen Victoria's death. This era, characterized by industrial progress, cultural growth, and expansion within the empire, began with her inheritance at the age of eighteen upon William IV's demise.",
      "method": "debate",
      "actual_response": "1837 to January 1901",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.4999957531690598e-05,
        "tree_retrieval": 4.846680891001597,
        "debate": 141.13189751503523,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 146.2030055001378,
      "bert_score": 0.8254584670066833,
      "f1_score": 0.13043478260869565,
      "rouge_score": 0.07547169811320753,
      "bleurt_score": -0.6375468373298645
    },
    {
      "query": "From where did many British colonists migrate to Florida?",
      "predicted_response": "coming from South Carolina, Georgia and England though there was also a group of settlers who came from the colony of Bermuda",
      "method": "exact-match",
      "actual_response": "coming from South Carolina, Georgia and England though there was also a group of settlers who came from the colony of Bermuda",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.15000070258975e-05,
        "tree_retrieval": 4.990541105973534,
        "debate": 141.13189751503523,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 5.1420042919926345,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.019597053527832
    },
    {
      "query": "When was an investigation conducted regarding school casualties?",
      "predicted_response": "December 2008",
      "method": "exact-match",
      "actual_response": "December 2008",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.060000017285347e-05,
        "tree_retrieval": 4.46435060899239,
        "debate": 141.13189751503523,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.668973916908726,
      "bert_score": 1.0000007152557373,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9750790596008301
    },
    {
      "query": "What term describes the competition among individuals of the more numerous sex for mating opportunities?",
      "predicted_response": "intrasexual competition",
      "method": "exact-match",
      "actual_response": "intrasexual competition",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0199997127056122e-05,
        "tree_retrieval": 4.424594301031902,
        "debate": 141.13189751503523,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.697389665991068,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9318580031394958
    },
    {
      "query": "What are the smaller streams used for?",
      "predicted_response": "draining the surrounding land",
      "method": "exact-match",
      "actual_response": "draining the surrounding land",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0499999411404133e-05,
        "tree_retrieval": 4.489557955996133,
        "debate": 141.13189751503523,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.6431497919838876,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0916777849197388
    },
    {
      "query": "What is the length of Catalina Highway in miles?",
      "predicted_response": "25",
      "method": "exact-match",
      "actual_response": "25",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.6899971999228e-05,
        "tree_retrieval": 4.435715097934008,
        "debate": 141.13189751503523,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.587515375111252,
      "bert_score": 0.999999463558197,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8044775724411011
    },
    {
      "query": "Why are consulting pharmacists more frequently engaging directly with patients?",
      "predicted_response": "because many elderly people are now taking numerous medications but continue to live outside of institutional settings",
      "method": "exact-match",
      "actual_response": "because many elderly people are now taking numerous medications but continue to live outside of institutional settings",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.859998494386673e-05,
        "tree_retrieval": 4.581217603990808,
        "debate": 141.13189751503523,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.805206875083968,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.023844838142395
    },
    {
      "query": "What did Romans prioritize over grave offerings in later times?",
      "predicted_response": "monumental endowments",
      "method": "exact-match",
      "actual_response": "monumental endowments",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0399998649954796e-05,
        "tree_retrieval": 4.749663935042918,
        "debate": 141.13189751503523,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.999218874843791,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0025385618209839
    },
    {
      "query": "Which song did Madonna face criticism for performing at the VMA?",
      "predicted_response": "\"Like a Virgin\"",
      "method": "exact-match",
      "actual_response": "\"Like a Virgin\"",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.789997961372137e-05,
        "tree_retrieval": 4.56725240801461,
        "debate": 141.13189751503523,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.719420291017741,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0594892501831055
    },
    {
      "query": "Which ores are most commonly used commercially?",
      "predicted_response": "In West Europe, minerals like hematite (Fe2O3), magnetite (Fe3O4), coal (bituminous varieties), chalcopyrite (CuFeS2), and others continue to hold commercial value due to their roles in steelmaking, energy generation, electronics, alloy strengthening, battery production, radiation shielding, and specialized medical devices. West Europe prioritizes the continuance of these vital resources while focusing on environmental stewardship.",
      "method": "debate",
      "actual_response": "sulfides",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0499999411404133e-05,
        "tree_retrieval": 4.420170098077506,
        "debate": 168.89511089096777,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 173.52995724999346,
      "bert_score": 0.7599231004714966,
      "f1_score": 0,
      "rouge_score": 0.0,
      "bleurt_score": -0.4981828033924103
    },
    {
      "query": "How would you define solar energy?",
      "predicted_response": "radiant light and heat from the Sun",
      "method": "exact-match",
      "actual_response": "radiant light and heat from the Sun",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.100093454122543e-05,
        "tree_retrieval": 4.966965054045431,
        "debate": 168.89511089096777,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 5.2053768329788,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0563148260116577
    },
    {
      "query": "Who was the first king of the Sumerian dynasty?",
      "predicted_response": "Etana",
      "method": "exact-match",
      "actual_response": "Etana",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9199989512562752e-05,
        "tree_retrieval": 4.451556460931897,
        "debate": 168.89511089096777,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.60445079091005,
      "bert_score": 0.9999994039535522,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.7926846742630005
    },
    {
      "query": "What kind of heritage is associated with Tyneside?",
      "predicted_response": "shipbuilding",
      "method": "exact-match",
      "actual_response": "shipbuilding",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.330005660653114e-05,
        "tree_retrieval": 4.4815076949307695,
        "debate": 168.89511089096777,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.64983845804818,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9190163612365723
    },
    {
      "query": "How did Gautama dedicate his life following his enlightenment?",
      "predicted_response": "he spent the rest of his life teaching the path of awakening he had discovered",
      "method": "exact-match",
      "actual_response": "he spent the rest of his life teaching the path of awakening he had discovered",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9999995604157448e-05,
        "tree_retrieval": 4.451333477045409,
        "debate": 168.89511089096777,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.656741250073537,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0260281562805176
    },
    {
      "query": "During which era, alongside the Renaissance, were the Middle Ages criticized?",
      "predicted_response": "Enlightenment",
      "method": "exact-match",
      "actual_response": "Enlightenment",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 9.310001041740179e-05,
        "tree_retrieval": 4.378340351046063,
        "debate": 168.89511089096777,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.560637833783403,
      "bert_score": 0.9999997019767761,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.892325758934021
    },
    {
      "query": "Who made up the bushi class?",
      "predicted_response": "ancient Japanese soldiers from traditional warrior families",
      "method": "exact-match",
      "actual_response": "ancient Japanese soldiers from traditional warrior families",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.220001235604286e-05,
        "tree_retrieval": 4.599575867061503,
        "debate": 168.89511089096777,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.78221445903182,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0583592653274536
    },
    {
      "query": "What primarily influences the state's climate?",
      "predicted_response": "elevation of the terrain",
      "method": "exact-match",
      "actual_response": "elevation of the terrain",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9799994081258774e-05,
        "tree_retrieval": 4.439872408984229,
        "debate": 168.89511089096777,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.592350875027478,
      "bert_score": 0.9999996423721313,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0602728128433228
    },
    {
      "query": "In which location can Al-Rashid Islamic Institute be found?",
      "predicted_response": "Cornwall, Ontario",
      "method": "exact-match",
      "actual_response": "Cornwall, Ontario",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0499999411404133e-05,
        "tree_retrieval": 4.388553798897192,
        "debate": 168.89511089096777,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.659778540953994,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9789361953735352
    },
    {
      "query": "Who stripped Japan's Buddhist monks of their weapons?",
      "predicted_response": "Oda Nobunaga",
      "method": "exact-match",
      "actual_response": "Oda Nobunaga",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.100000321865082e-05,
        "tree_retrieval": 4.400412805960514,
        "debate": 168.89511089096777,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.5682814999017864,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.903240442276001
    },
    {
      "query": "What sports facility was established in 1952?",
      "predicted_response": "Wutaishan Sports Center",
      "method": "exact-match",
      "actual_response": "Wutaishan Sports Center",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8900918550789356e-05,
        "tree_retrieval": 4.39704743900802,
        "debate": 168.89511089096777,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.619157332926989,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.960528552532196
    },
    {
      "query": "Who were the Normans' allies in Anatolia?",
      "predicted_response": "Turkish forces",
      "method": "exact-match",
      "actual_response": "Turkish forces",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.989999484270811e-05,
        "tree_retrieval": 4.405207514995709,
        "debate": 168.89511089096777,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.5582765829749405,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9800757169723511
    },
    {
      "query": "In which part of Florida is Miami situated?",
      "predicted_response": "Miami is located in southeastern Florida, USA. Climate change affects tourism in both European coastal cities like Amsterdam and destinations within Florida such as Miami-Dade County. Both regions face similar environmental challenges due to their proximity to water bodies, including rising sea levels and extreme weather events. A global perspective is needed to address the impacts of climate change on tourism, with adaptable strategies for resilience and sustainable growth that preserve ecological and cultural assets.",
      "method": "debate",
      "actual_response": "southeastern",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8499984182417393e-05,
        "tree_retrieval": 4.385463188984431,
        "debate": 218.60226310498547,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 223.22504408401437,
      "bert_score": 0.7946282625198364,
      "f1_score": 0.027027027027027025,
      "rouge_score": 0.025974025974025976,
      "bleurt_score": -0.2484675496816635
    },
    {
      "query": "What was initially thought to be the cause of the Black Death?",
      "predicted_response": "the heavens",
      "method": "exact-match",
      "actual_response": "the heavens",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.619996227324009e-05,
        "tree_retrieval": 5.116920938948169,
        "debate": 218.60226310498547,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 5.293569000205025,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0002719163894653
    },
    {
      "query": "Which aspect of treaties frequently requires interpretation when unclear?",
      "predicted_response": "The language",
      "method": "exact-match",
      "actual_response": "The language",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.95999925583601e-05,
        "tree_retrieval": 4.552503800019622,
        "debate": 218.60226310498547,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.706335166934878,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9898022413253784
    },
    {
      "query": "What are churches filled with monuments to?",
      "predicted_response": "monuments to the prosperous",
      "method": "exact-match",
      "actual_response": "monuments to the prosperous",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.090000245720148e-05,
        "tree_retrieval": 4.438790517975576,
        "debate": 218.60226310498547,
        "global_llm": 1.596646261983551
      },
      "overall_latency": 4.591057917103171,
      "bert_score": 0.9999996423721313,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0703485012054443
    },
    {
      "query": "What are yours?",
      "predicted_response": "Could you please provide more context or specify what you are referring to with \"yours\"? This will help me give a more accurate response.",
      "method": "global-llm",
      "actual_response": "fairs held at the shrines of Sufi saints",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1400006264448166e-05,
        "tree_retrieval": 4.630378335015848,
        "debate": 218.60226310498547,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 6.408488167217001,
      "bert_score": 0.8144024014472961,
      "f1_score": 0,
      "rouge_score": 0.0,
      "bleurt_score": -1.1154173612594604
    },
    {
      "query": "Who was unaware of the initial potential revenue the program could generate?",
      "predicted_response": "the public",
      "method": "exact-match",
      "actual_response": "the public",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.220001235604286e-05,
        "tree_retrieval": 4.783079674933106,
        "debate": 218.60226310498547,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.999706333037466,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0246869325637817
    },
    {
      "query": "What tree, other than a palm, is featured on the crest?",
      "predicted_response": "laurel",
      "method": "exact-match",
      "actual_response": "laurel",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.120000474154949e-05,
        "tree_retrieval": 4.4758573999861255,
        "debate": 218.60226310498547,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.6281140830833465,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.7769014239311218
    },
    {
      "query": "What is Mary Wollstonecraft's most famous work?",
      "predicted_response": "A Vindication of the Rights of Woman (1791)",
      "method": "exact-match",
      "actual_response": "A Vindication of the Rights of Woman (1791)",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.859998494386673e-05,
        "tree_retrieval": 4.466190110892057,
        "debate": 218.60226310498547,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.6466349579859525,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.057505488395691
    },
    {
      "query": "How does the capabilities approach view poverty?",
      "predicted_response": "capability deprivation",
      "method": "exact-match",
      "actual_response": "capability deprivation",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.719997428357601e-05,
        "tree_retrieval": 4.64988166000694,
        "debate": 218.60226310498547,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.801411416847259,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0638427734375
    },
    {
      "query": "Which early architectural text originated in India?",
      "predicted_response": "Shilpa Shastras",
      "method": "exact-match",
      "actual_response": "Shilpa Shastras",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.170000854879618e-05,
        "tree_retrieval": 4.627366978907958,
        "debate": 218.60226310498547,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.8162292500492185,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9498510956764221
    },
    {
      "query": "During which year did Fresno receive the highest amount of rainfall?",
      "predicted_response": "1885",
      "method": "exact-match",
      "actual_response": "1885",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.889998722821474e-05,
        "tree_retrieval": 4.6459221719997,
        "debate": 218.60226310498547,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.8214577089529485,
      "bert_score": 1.0000003576278687,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8516998887062073
    },
    {
      "query": "What are some of the most frequent triggers?",
      "predicted_response": "allergens, smoke (tobacco and other), air pollution, non selective beta-blockers, and sulfite-containing foods",
      "method": "exact-match",
      "actual_response": "allergens, smoke (tobacco and other), air pollution, non selective beta-blockers, and sulfite-containing foods",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.6999972760677338e-05,
        "tree_retrieval": 4.535509675042704,
        "debate": 218.60226310498547,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.734692333964631,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.047251582145691
    },
    {
      "query": "What is the duration of the rebirth cycle mentioned in the Vedas?",
      "predicted_response": "4,320,000 years",
      "method": "exact-match",
      "actual_response": "4,320,000 years",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.719997428357601e-05,
        "tree_retrieval": 4.51904977101367,
        "debate": 218.60226310498547,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.671559124952182,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0581315755844116
    },
    {
      "query": "Which transformation maps a point in the square to its corresponding point under symmetry?",
      "predicted_response": "functions",
      "method": "exact-match",
      "actual_response": "functions",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.269989974796772e-05,
        "tree_retrieval": 4.513092688983306,
        "debate": 218.60226310498547,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.665502666030079,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9022408723831177
    },
    {
      "query": "What contributed to spreading Greek culture beyond its borders?",
      "predicted_response": "Greeks spread their culture extensively through colonization and trade, largely due to military campaigns such as those led by Alexander the Great. Colonies established in Southern Italy, Asia Minor, and Mediterranean islands served as conduits for Hellenic customs while fostering cultural exchanges through language usage. This blending of cultures is reflected in pottery decorations and temple architecture. City centers during this era became vibrant hubs for trade and cultural synthesis, enabling Greek customs, language, religion, and artistic expressions to permeate regions far beyond traditional Hellenic territories. This interplay between colonization activities and cultural diffusion expanded Greek influence into distant lands like Sicily and Italian coastal regions, shaping a legacy of multicultural cohabitation where Hellenic identity was shaped by and contributed to various cultures across continents.",
      "method": "debate",
      "actual_response": "the trading and colonizing activities of the Greek tribes and city states spread the Greek culture, religion and language",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1400006264448166e-05,
        "tree_retrieval": 4.563038352993317,
        "debate": 206.39908552204724,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 211.16854970878921,
      "bert_score": 0.8628708124160767,
      "f1_score": 0.17266187050359716,
      "rouge_score": 0.1111111111111111,
      "bleurt_score": -0.015080229379236698
    },
    {
      "query": "How is man consistently perceived?",
      "predicted_response": "Humans transcend superficial markers such as physical appearance, with complex personalities. Historical understandings often relied on flawed categorizations based on race, perpetuating misconceptions and inequality. We should appreciate individual uniqueness, recognizing that our perception of 'man' shouldn't be limited by these factors or historical conceptions. Celebrate diversity within identities, valuing the richness within shared humanity beyond antiquated beliefs of differentiation based on appearance or geography. This conscious recognition is key to building an equitable society that values individuals beyond outdated beliefs.",
      "method": "debate",
      "actual_response": "an image of God",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0399998649954796e-05,
        "tree_retrieval": 5.386390777071938,
        "debate": 222.2271150930319,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 227.8180890418589,
      "bert_score": 0.8156615495681763,
      "f1_score": 0.024390243902439022,
      "rouge_score": 0.023255813953488372,
      "bleurt_score": -0.8003607988357544
    },
    {
      "query": "In what ways do genetic alterations impact plants?",
      "predicted_response": "express themselves\") differently",
      "method": "exact-match",
      "actual_response": "express themselves\") differently",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.11010517179966e-05,
        "tree_retrieval": 4.916779235936701,
        "debate": 222.2271150930319,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 5.20896445796825,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0786851644515991
    },
    {
      "query": "What themes are commonly explored in a tragedy?",
      "predicted_response": "historical or mythological themes",
      "method": "exact-match",
      "actual_response": "historical or mythological themes",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.2199895940721035e-05,
        "tree_retrieval": 4.6199806270888075,
        "debate": 222.2271150930319,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.775745915947482,
      "bert_score": 1.0000003576278687,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0338842868804932
    },
    {
      "query": "How many Oscars did 'Jaws' receive?",
      "predicted_response": "Jaws won 3 Oscars.",
      "method": "debate",
      "actual_response": "three",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.190001007169485e-05,
        "tree_retrieval": 4.487814764957875,
        "debate": 133.8255593170179,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 138.5282213750761,
      "bert_score": 0.8261136412620544,
      "f1_score": 0,
      "rouge_score": 0.0,
      "bleurt_score": -1.0620354413986206
    },
    {
      "query": "In which location in Oklahoma can you find a notable Egyptian art collection?",
      "predicted_response": "Mabee-Gerrer Museum of Art in Shawnee",
      "method": "exact-match",
      "actual_response": "Mabee-Gerrer Museum of Art in Shawnee",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.7799978852272034e-05,
        "tree_retrieval": 4.815309333032928,
        "debate": 133.8255593170179,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.96700529102236,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0167642831802368
    },
    {
      "query": "Who provides financial support for these homeless shelters?",
      "predicted_response": "the city",
      "method": "exact-match",
      "actual_response": "the city",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.130000550299883e-05,
        "tree_retrieval": 4.562551505980082,
        "debate": 133.8255593170179,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.847596040926874,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9600675106048584
    },
    {
      "query": "What kind of group were the \"king's friends\"?",
      "predicted_response": "neo-Tory",
      "method": "exact-match",
      "actual_response": "neo-Tory",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1400006264448166e-05,
        "tree_retrieval": 4.569791966932826,
        "debate": 133.8255593170179,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.722183207981288,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0007683038711548
    },
    {
      "query": "What purpose did Luther believe God had for sending the Turks?",
      "predicted_response": "destroy the antichrist",
      "method": "exact-match",
      "actual_response": "destroy the antichrist",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.2299932576715946e-05,
        "tree_retrieval": 4.829365785932168,
        "debate": 133.8255593170179,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 5.034575332887471,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0476640462875366
    },
    {
      "query": "For what purpose has pain occasionally been cited as a reason to grant terminally ill patients a right?",
      "predicted_response": "end their lives",
      "method": "exact-match",
      "actual_response": "end their lives",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.200001083314419e-05,
        "tree_retrieval": 4.579372741980478,
        "debate": 133.8255593170179,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.802820791024715,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.080140471458435
    },
    {
      "query": "How is all waste from university landscaping utilized?",
      "predicted_response": "composted",
      "method": "exact-match",
      "actual_response": "composted",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.170000854879618e-05,
        "tree_retrieval": 4.54397971497383,
        "debate": 133.8255593170179,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.696958084125072,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9960067272186279
    },
    {
      "query": "Who was the Cubs' manager in 1969?",
      "predicted_response": "Vincent \"Sparky\" Morgan managed the Chicago Cubs in 1969, but Bobby Tolan temporarily replaced him during a crucial phase of the season. Despite this, the team qualified for the World Series. However, they did not secure victory. For more detailed information on this subject matter that extends past the year mentioned and after April 2024, consult credible historical sports documentation or databases such as MLB's official records.",
      "method": "debate",
      "actual_response": "Leo Durocher",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.120000474154949e-05,
        "tree_retrieval": 4.498553374083713,
        "debate": 203.65450959699228,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 208.3684327499941,
      "bert_score": 0.7499182820320129,
      "f1_score": 0,
      "rouge_score": 0.0,
      "bleurt_score": -0.7640320062637329
    },
    {
      "query": "In which product did zinc compounds exhibit minimal differences in absorption?",
      "predicted_response": "maize tortillas",
      "method": "exact-match",
      "actual_response": "maize tortillas",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0099996365606785e-05,
        "tree_retrieval": 4.876366329961456,
        "debate": 203.65450959699228,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 5.028167250100523,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0125677585601807
    },
    {
      "query": "When might the dielectric's polarization fail to keep up with the voltage?",
      "predicted_response": "driven with a time-varying voltage that changes rapidly",
      "method": "exact-match",
      "actual_response": "driven with a time-varying voltage that changes rapidly",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.95999925583601e-05,
        "tree_retrieval": 4.5888126119971275,
        "debate": 203.65450959699228,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.741183917038143,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0709419250488281
    },
    {
      "query": "What is the current name of the country formerly known as South-West Africa?",
      "predicted_response": "Namibia",
      "method": "exact-match",
      "actual_response": "Namibia",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8499984182417393e-05,
        "tree_retrieval": 4.53479373594746,
        "debate": 203.65450959699228,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.706469958182424,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8646789789199829
    },
    {
      "query": "What is the frequency of XPT departures to Sydney?",
      "predicted_response": "twice a day",
      "method": "exact-match",
      "actual_response": "twice a day",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.03010456264019e-05,
        "tree_retrieval": 4.775514290085994,
        "debate": 203.65450959699228,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.964880874846131,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0704240798950195
    },
    {
      "query": "Can antibiotics affect the effectiveness of birth control pills?",
      "predicted_response": "The majority of studies indicate antibiotics do interfere with contraceptive pills",
      "method": "exact-match",
      "actual_response": "The majority of studies indicate antibiotics do interfere with contraceptive pills",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.720009069889784e-05,
        "tree_retrieval": 4.598374220891856,
        "debate": 203.65450959699228,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.750087874941528,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0645235776901245
    },
    {
      "query": "What is the number of propositions that constitute the separationist stance on the Establishment Clause?",
      "predicted_response": "two",
      "method": "exact-match",
      "actual_response": "two",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8699985705316067e-05,
        "tree_retrieval": 4.545676913927309,
        "debate": 203.65450959699228,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.721403541974723,
      "bert_score": 0.9999997019767761,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.7901197671890259
    },
    {
      "query": "Which area is referred to as Jhamel?",
      "predicted_response": "Jhamsikhel",
      "method": "exact-match",
      "actual_response": "Jhamsikhel",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.95999925583601e-05,
        "tree_retrieval": 4.43334552005399,
        "debate": 203.65450959699228,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.585721333045512,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8741967678070068
    },
    {
      "query": "What is the number of Methodist churches in Plymouth?",
      "predicted_response": "over twenty",
      "method": "exact-match",
      "actual_response": "over twenty",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.100000321865082e-05,
        "tree_retrieval": 4.497372066020034,
        "debate": 203.65450959699228,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.706488250056282,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0919932126998901
    },
    {
      "query": "From where did the next group of settlers on Norfolk Island originate?",
      "predicted_response": "the Pitcairn Islands",
      "method": "exact-match",
      "actual_response": "the Pitcairn Islands",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.090000245720148e-05,
        "tree_retrieval": 4.614832155057229,
        "debate": 203.65450959699228,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.903120999922976,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9747878313064575
    },
    {
      "query": "Which record company signed the season fourteen winner of American Idol?",
      "predicted_response": "Big Machine Records",
      "method": "exact-match",
      "actual_response": "Big Machine Records",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.170000854879618e-05,
        "tree_retrieval": 4.653314578928985,
        "debate": 203.65450959699228,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.804747250163928,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9588057398796082
    },
    {
      "query": "Who governed Egypt during the Suez Crisis?",
      "predicted_response": "Gamal Abdel Nasser",
      "method": "exact-match",
      "actual_response": "Gamal Abdel Nasser",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8799986466765404e-05,
        "tree_retrieval": 4.739555980893783,
        "debate": 203.65450959699228,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.943107167026028,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9351990222930908
    },
    {
      "query": "Which Doctor was initially called \"his secret\"?",
      "predicted_response": "the War Doctor",
      "method": "exact-match",
      "actual_response": "the War Doctor",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9999995604157448e-05,
        "tree_retrieval": 4.571314509958029,
        "debate": 203.65450959699228,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.780219790991396,
      "bert_score": 1.0000003576278687,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0153037309646606
    },
    {
      "query": "When did the last Greek resistance occur?",
      "predicted_response": "The last significant act of organized, armed resistance in Greece during World War II was led by Napoleon Zervas and conducted by EDES until May 1945, marking the end of large-scale organized armed resistance following a ceasefire agreement with Italy as Germany surrendered to Allied forces.",
      "method": "debate",
      "actual_response": "88 BC",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8699985705316067e-05,
        "tree_retrieval": 4.528094307985157,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 143.8503512921743,
      "bert_score": 0.8048138618469238,
      "f1_score": 0,
      "rouge_score": 0.0,
      "bleurt_score": -0.8713565468788147
    },
    {
      "query": "What type of district does the San Bernardino - Riverside area have?",
      "predicted_response": "business",
      "method": "exact-match",
      "actual_response": "business",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.169989213347435e-05,
        "tree_retrieval": 4.797406035009772,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.98570437496528,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8863682746887207
    },
    {
      "query": "Who are the heads of each house tasked with updating their group on the governor-general's actions?",
      "predicted_response": "President of the Senate and the Speaker of the House of Representatives",
      "method": "exact-match",
      "actual_response": "President of the Senate and the Speaker of the House of Representatives",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.589996438473463e-05,
        "tree_retrieval": 4.485236347070895,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.6734960419125855,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0583747625350952
    },
    {
      "query": "After the death of which religious figure did General Dupuy disclose Napoleon's reasons for religious tolerance?",
      "predicted_response": "Pope Pius VI",
      "method": "exact-match",
      "actual_response": "Pope Pius VI",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.319994382560253e-05,
        "tree_retrieval": 4.468875832972117,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.620716542005539,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9734905362129211
    },
    {
      "query": "What appears on the Start Screen?",
      "predicted_response": "a customizable array of tiles linking to various apps and desktop programs",
      "method": "exact-match",
      "actual_response": "a customizable array of tiles linking to various apps and desktop programs",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8099981136620045e-05,
        "tree_retrieval": 4.694813032983802,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.904012042097747,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0660301446914673
    },
    {
      "query": "What did Philo's opinions on the lack of instruments conflict with?",
      "predicted_response": "Jewish scriptures",
      "method": "exact-match",
      "actual_response": "Jewish scriptures",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0200928449630737e-05,
        "tree_retrieval": 4.731389838038012,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.8835766250267625,
      "bert_score": 1.0000004768371582,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9773221015930176
    },
    {
      "query": "When was A Study of High Definition Television Systems published?",
      "predicted_response": "1979",
      "method": "exact-match",
      "actual_response": "1979",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8199981898069382e-05,
        "tree_retrieval": 4.577394727966748,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.76956016686745,
      "bert_score": 1.0000004768371582,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8253446817398071
    },
    {
      "query": "What was the intended equivalent value of one dollar?",
      "predicted_response": "a Spanish milled dollar",
      "method": "exact-match",
      "actual_response": "a Spanish milled dollar",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.3000949770212173e-05,
        "tree_retrieval": 4.654256296926178,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.806074999971315,
      "bert_score": 0.9999996423721313,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0727546215057373
    },
    {
      "query": "How much would disease incidence decrease with improved water and sanitation?",
      "predicted_response": "22\u201327% reduction in disease incidence",
      "method": "exact-match",
      "actual_response": "22\u201327% reduction in disease incidence",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1100003980100155e-05,
        "tree_retrieval": 4.565674323006533,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.774222832871601,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0818818807601929
    },
    {
      "query": "What qualifications might the Government mandate for a teacher to begin teaching?",
      "predicted_response": "certification by a recognized body",
      "method": "exact-match",
      "actual_response": "certification by a recognized body",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.070000093430281e-05,
        "tree_retrieval": 4.644405283033848,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.884201624896377,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0649981498718262
    },
    {
      "query": "By whom was Foot replaced?",
      "predicted_response": "Neil Kinnock",
      "method": "exact-match",
      "actual_response": "Neil Kinnock",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1100003980100155e-05,
        "tree_retrieval": 4.600417581037618,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.778097291942686,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9083579778671265
    },
    {
      "query": "What is the distance to Canelones' neighboring capital?",
      "predicted_response": "46 kilometres",
      "method": "exact-match",
      "actual_response": "46 kilometres",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.220001235604286e-05,
        "tree_retrieval": 4.502935576019809,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.690677416045219,
      "bert_score": 0.9999997019767761,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0099753141403198
    },
    {
      "query": "Against what was Jefferson's Statute of Religious Freedom drafted?",
      "predicted_response": "a bill",
      "method": "exact-match",
      "actual_response": "a bill",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.250001464039087e-05,
        "tree_retrieval": 4.794738919939846,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.990194374928251,
      "bert_score": 1.0000005960464478,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0194571018218994
    },
    {
      "query": "Who are the artists that influenced Madonna?",
      "predicted_response": "Frida Kahlo",
      "method": "exact-match",
      "actual_response": "Frida Kahlo",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.989999484270811e-05,
        "tree_retrieval": 4.537796720047481,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.79187895799987,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9176698923110962
    },
    {
      "query": "Which sector has the smallest workforce?",
      "predicted_response": "Industry and manufacturing",
      "method": "exact-match",
      "actual_response": "Industry and manufacturing",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.130000550299883e-05,
        "tree_retrieval": 4.482673621037975,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.6371087920852005,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0037364959716797
    },
    {
      "query": "Which Gran Turismo game was unveiled in 2007 but released later?",
      "predicted_response": "Gran Turismo 5 Prologue",
      "method": "exact-match",
      "actual_response": "Gran Turismo 5 Prologue",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.3200055845081806e-05,
        "tree_retrieval": 4.571872451109812,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.745134042110294,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.009635090827942
    },
    {
      "query": "During which years was the civil war fought?",
      "predicted_response": "1992 to 1997",
      "method": "exact-match",
      "actual_response": "1992 to 1997",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.100000321865082e-05,
        "tree_retrieval": 4.612762943957932,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.7653922501485795,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0169957876205444
    },
    {
      "query": "What color, besides lemon yellow, is found in uranium glass?",
      "predicted_response": "orange-red",
      "method": "exact-match",
      "actual_response": "orange-red",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.270001616328955e-05,
        "tree_retrieval": 4.610705800005235,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.816912083188072,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0518840551376343
    },
    {
      "query": "Which game, popular in both Britain and America, is gaining popularity in pubs?",
      "predicted_response": "pool",
      "method": "exact-match",
      "actual_response": "pool",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1100003980100155e-05,
        "tree_retrieval": 4.586013944004662,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.797159833135083,
      "bert_score": 1.0000003576278687,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.7722023725509644
    },
    {
      "query": "Which location in Miami was considered for hosting Super Bowl 50?",
      "predicted_response": "Sun Life Stadium",
      "method": "exact-match",
      "actual_response": "Sun Life Stadium",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.95999925583601e-05,
        "tree_retrieval": 4.5725327170221135,
        "debate": 139.11542427295353,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 5.10971129196696,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9539350271224976
    },
    {
      "query": "What year did John pass away?",
      "predicted_response": "Pope John XXIII died on October 18, 2013 at approximately 81 years old. His papacy began prior to his death, and he was elected on November 28th of the preceding year.",
      "method": "debate",
      "actual_response": "18 October",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.95999925583601e-05,
        "tree_retrieval": 4.76350229291711,
        "debate": 107.02838884899393,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 111.94327233405784,
      "bert_score": 0.8351849913597107,
      "f1_score": 0.125,
      "rouge_score": 0.06060606060606061,
      "bleurt_score": -0.7254531383514404
    },
    {
      "query": "What did Popper claim to be objective and independent of its subject?",
      "predicted_response": "Knowledge, in the philosophical sense according to Karl Popper, has an objective character independent of individual subjectivity and personal experience, supported by his emphasis on falsifiability for rigorous scrutiny. This allows scientific knowledge to withstand universal examination without relying on subjective experiences. Furthermore, Popper aimed to differentiate genuine scientific theories from those misused by totalitarian regimes like fascism and Nazism in Europe. The independence of knowledge is crucial, not only philosophically but also practically, as it maintains scientific integrity against politicization or misuse by regimes promoting oppressive ideologies.",
      "method": "debate",
      "actual_response": "knowledge",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 4.970002919435501e-05,
        "tree_retrieval": 4.874053371022455,
        "debate": 129.61844758689404,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 134.6519260830246,
      "bert_score": 0.7863683700561523,
      "f1_score": 0.023255813953488372,
      "rouge_score": 0.02247191011235955,
      "bleurt_score": 0.0844024270772934
    },
    {
      "query": "Who is recognized for the belief that humanity holds the utmost importance in the world?",
      "predicted_response": "Wu of Zhou",
      "method": "exact-match",
      "actual_response": "Wu of Zhou",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.120000474154949e-05,
        "tree_retrieval": 4.8812541590305045,
        "debate": 129.61844758689404,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 5.092621958116069,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9416054487228394
    },
    {
      "query": "What does ECCE mean in the context of Swazi education?",
      "predicted_response": "early childhood care and education",
      "method": "exact-match",
      "actual_response": "early childhood care and education",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.820009831339121e-05,
        "tree_retrieval": 4.519053998985328,
        "debate": 129.61844758689404,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.672392707783729,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.029485821723938
    },
    {
      "query": "What became unpopular during this period?",
      "predicted_response": "Grandiose projects undertaken by leadership during economic hardship are often perceived as extravagant and offering minimal immediate benefits. Systemic issues like regional instability or fragmented political landscapes also foster unpopularity, particularly during periods of economic decline. These factors contribute to public discontent in various contexts throughout history.",
      "method": "debate",
      "actual_response": "Wood-panelling",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.859998494386673e-05,
        "tree_retrieval": 4.680223391042091,
        "debate": 167.5571987599833,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 172.5130150418263,
      "bert_score": 0.785793125629425,
      "f1_score": 0,
      "rouge_score": 0.0,
      "bleurt_score": -0.820380449295044
    },
    {
      "query": "What type of art held significance in religious symbolism and decoration during the Ottoman Empire?",
      "predicted_response": "carpet weaving",
      "method": "exact-match",
      "actual_response": "carpet weaving",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.160000778734684e-05,
        "tree_retrieval": 4.856938921962865,
        "debate": 167.5571987599833,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 5.085182917071506,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9661898612976074
    },
    {
      "query": "In what year was the International Chopin Piano Competition founded?",
      "predicted_response": "1927",
      "method": "exact-match",
      "actual_response": "1927",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.220097955316305e-05,
        "tree_retrieval": 4.401702611008659,
        "debate": 167.5571987599833,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.57585662486963,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8661757707595825
    },
    {
      "query": "In what year did Seoul Semiconductor launch the first high DC voltage LED?",
      "predicted_response": "2009",
      "method": "exact-match",
      "actual_response": "2009",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.200001083314419e-05,
        "tree_retrieval": 4.658331804908812,
        "debate": 167.5571987599833,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.890241584042087,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.827873945236206
    },
    {
      "query": "What led to the formation of different Protestant branches?",
      "predicted_response": "how they have been influenced by important movements since the Reformation",
      "method": "exact-match",
      "actual_response": "how they have been influenced by important movements since the Reformation",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.219993181526661e-05,
        "tree_retrieval": 4.853590909042396,
        "debate": 167.5571987599833,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 5.004898334154859,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0421985387802124
    },
    {
      "query": "What is a typical background for a Japanese wrestler?",
      "predicted_response": "legitimate martial arts",
      "method": "exact-match",
      "actual_response": "legitimate martial arts",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.5499961338937283e-05,
        "tree_retrieval": 4.474474959075451,
        "debate": 167.5571987599833,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.6849603748414665,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0100258588790894
    },
    {
      "query": "What enhancement did Germany make to the 20 mm to increase its effectiveness?",
      "predicted_response": "a 3.7 cm",
      "method": "exact-match",
      "actual_response": "a 3.7 cm",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.200001083314419e-05,
        "tree_retrieval": 4.530677319969982,
        "debate": 167.5571987599833,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.779816458933055,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.1065832376480103
    },
    {
      "query": "How many RIAA certifications has Beyonc\u00e9 received?",
      "predicted_response": "Beyonc\u00e9 has received 64 RIAA certifications for her diverse body of work that resonates with listeners worldwide. She encapsulates empowerment and social commentary in songs like \"Single Ladies\" and \"Formation,\" contributing to prestigious organizations such as the RIAA's acclaims.",
      "method": "debate",
      "actual_response": "64",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9999995604157448e-05,
        "tree_retrieval": 4.5588780749822035,
        "debate": 96.44468047004193,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 101.19763308390975,
      "bert_score": 0.7902594208717346,
      "f1_score": 0.05128205128205127,
      "rouge_score": 0.04878048780487806,
      "bleurt_score": -0.6790798306465149
    },
    {
      "query": "How did Lothar Wolfgang Nordheim characterize von Neumann?",
      "predicted_response": "\"fastest mind I ever met\",",
      "method": "exact-match",
      "actual_response": "\"fastest mind I ever met\",",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.130000550299883e-05,
        "tree_retrieval": 4.881896947976202,
        "debate": 96.44468047004193,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 5.154503458878025,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0544222593307495
    },
    {
      "query": "When was the importance of \"separation\" to the Constitution's Religion Clauses clearly stated?",
      "predicted_response": "1947",
      "method": "exact-match",
      "actual_response": "1947",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0199997127056122e-05,
        "tree_retrieval": 4.561924753012136,
        "debate": 96.44468047004193,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.774662708863616,
      "bert_score": 1.0000003576278687,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.826357364654541
    },
    {
      "query": "How does bronchial thermoplasty impact patients?",
      "predicted_response": "it appears to decrease the subsequent rate.",
      "method": "exact-match",
      "actual_response": "it appears to decrease the subsequent rate.",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.150093834847212e-05,
        "tree_retrieval": 4.487150119035505,
        "debate": 96.44468047004193,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.689383333083242,
      "bert_score": 0.9999997019767761,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0987862348556519
    },
    {
      "query": "Randomly selected individuals from various groups might share more similarities with each other than with members of their own what?",
      "predicted_response": "cluster",
      "method": "exact-match",
      "actual_response": "cluster",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 4.520104266703129e-05,
        "tree_retrieval": 4.746187351993285,
        "debate": 96.44468047004193,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.98922058288008,
      "bert_score": 0.9999998211860657,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.7862832546234131
    },
    {
      "query": "Who led the Puritans as their religious figure during their initial settlement?",
      "predicted_response": "John Winthrop led Puritans as their religious figure from around 1630 until his resignation due to old age circa 1659. He advocated for a society reflecting God's law, deeply rooted in Puritan ideals. His vision of 'a city upon a hill' resonated with English dissenters seeking freedom and self-governance across the Atlantic. While Reverend John Davenport led religious communities within Salem Colony during the same timeframe, Winthrop's leadership was broader, encompassing governance and social cohesion within Massachusetts Bay Colony as a whole.",
      "method": "debate",
      "actual_response": "Reverend John Davenport",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1100003980100155e-05,
        "tree_retrieval": 4.646340517909266,
        "debate": 198.88143763504922,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 203.74870979087427,
      "bert_score": 0.8234567046165466,
      "f1_score": 0.07594936708860758,
      "rouge_score": 0.06818181818181818,
      "bleurt_score": -0.45199403166770935
    },
    {
      "query": "What occurred with Sky's contract in 2006?",
      "predicted_response": "Sky's monopoly was broken from August 2006 when Setanta Sports was awarded rights to show two out of the six packages of matches available.",
      "method": "exact-match",
      "actual_response": "Sky's monopoly was broken from August 2006 when Setanta Sports was awarded rights to show two out of the six packages of matches available.",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.070000093430281e-05,
        "tree_retrieval": 4.931476036901586,
        "debate": 198.88143763504922,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 5.082552042091265,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0342332124710083
    },
    {
      "query": "What relates mass to space-time?",
      "predicted_response": "General relativity",
      "method": "exact-match",
      "actual_response": "General relativity",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.95999925583601e-05,
        "tree_retrieval": 4.543191515025683,
        "debate": 198.88143763504922,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.798389124916866,
      "bert_score": 0.9999995827674866,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9292874336242676
    },
    {
      "query": "Which German coast did the RAF bomb?",
      "predicted_response": "Wilhelmshaven",
      "method": "exact-match",
      "actual_response": "Wilhelmshaven",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9499991796910763e-05,
        "tree_retrieval": 4.617445326060988,
        "debate": 198.88143763504922,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.792083624983206,
      "bert_score": 0.9999998211860657,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9161422252655029
    },
    {
      "query": "What are the three tiers of higher education in Estonia?",
      "predicted_response": "bachelor's, master's, and doctoral studies",
      "method": "exact-match",
      "actual_response": "bachelor's, master's, and doctoral studies",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.4399952962994576e-05,
        "tree_retrieval": 4.547183190006763,
        "debate": 198.88143763504922,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.87244649999775,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.071853518486023
    },
    {
      "query": "What class does the Sao Paulo aircraft carrier belong to?",
      "predicted_response": "Clemenceau",
      "method": "exact-match",
      "actual_response": "Clemenceau",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.120000474154949e-05,
        "tree_retrieval": 4.550636162981391,
        "debate": 198.88143763504922,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.702959042042494,
      "bert_score": 0.9999998211860657,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8548162579536438
    },
    {
      "query": "What is another name for abstract expressionism?",
      "predicted_response": "the New York School",
      "method": "exact-match",
      "actual_response": "the New York School",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.130105324089527e-05,
        "tree_retrieval": 4.782974041998386,
        "debate": 198.88143763504922,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.935579082928598,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9987560510635376
    },
    {
      "query": "What was the impact of the civil war on Afghanistan's economy?",
      "predicted_response": "one of the poorest countries on earth",
      "method": "exact-match",
      "actual_response": "one of the poorest countries on earth",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.029999788850546e-05,
        "tree_retrieval": 4.615393207059242,
        "debate": 198.88143763504922,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.816283291904256,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0825549364089966
    },
    {
      "query": "Who were the two other renowned artists in the Super Bowl 50 halftime show?",
      "predicted_response": "Bruno Mars performed solo at Super Bowl 50, then collaborated with Beyonc\u00e9 and Shakira for the halftime show. They performed a medley of hits from their careers, including \"Uptown Funk,\" alongside Mark Ronson.",
      "method": "debate",
      "actual_response": "Beyonc\u00e9 and Bruno Mars",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.130105324089527e-05,
        "tree_retrieval": 4.554147489950992,
        "debate": 153.3264330039965,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 158.06986770802177,
      "bert_score": 0.8574596643447876,
      "f1_score": 0.2285714285714286,
      "rouge_score": 0.10810810810810813,
      "bleurt_score": -0.24140192568302155
    },
    {
      "query": "Who was the top pick in the 1998 NFL draft?",
      "predicted_response": "Manning",
      "method": "exact-match",
      "actual_response": "Manning",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.270001616328955e-05,
        "tree_retrieval": 5.132832950912416,
        "debate": 153.3264330039965,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 5.315277417190373,
      "bert_score": 1.0000003576278687,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8551865816116333
    },
    {
      "query": "In which year was Tem\u00fcjin, later known as Genghis Khan, probably born?",
      "predicted_response": "1162 in Del\u00fc\u00fcn Boldog (Mongolia) is where Tem\u00fcjin was likely born.",
      "method": "debate",
      "actual_response": "1162",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.789997961372137e-05,
        "tree_retrieval": 4.357045836979523,
        "debate": 67.4090358519461,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 71.91831083293073,
      "bert_score": 0.8299838304519653,
      "f1_score": 0.16666666666666669,
      "rouge_score": 0.14285714285714288,
      "bleurt_score": -0.759055495262146
    },
    {
      "query": "What is the third type of content available at Home besides free and won?",
      "predicted_response": "premium",
      "method": "exact-match",
      "actual_response": "premium",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1800009310245514e-05,
        "tree_retrieval": 4.743904662900604,
        "debate": 67.4090358519461,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.925259750103578,
      "bert_score": 0.9999997019767761,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9303838014602661
    },
    {
      "query": "Who held the Arena Football League championship title previously?",
      "predicted_response": "San Jose SaberCats",
      "method": "exact-match",
      "actual_response": "San Jose SaberCats",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0099996365606785e-05,
        "tree_retrieval": 4.411075072945096,
        "debate": 67.4090358519461,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.57972375000827,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9809756278991699
    },
    {
      "query": "To which civilization did the pottery belong?",
      "predicted_response": "Timucua",
      "method": "exact-match",
      "actual_response": "Timucua",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0900933779776096e-05,
        "tree_retrieval": 4.472347442060709,
        "debate": 67.4090358519461,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.6814115000888705,
      "bert_score": 1.0000003576278687,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8536363244056702
    },
    {
      "query": "In which neighborhood is the Marriott Starr Pass Resort & Spa located?",
      "predicted_response": "The Marriott Starr Pass Resort & Spa is located in Starr Pass, near Grand Canyon National Park attractions such as Big Sky Resort, providing a scenic and natural getaway experience.",
      "method": "debate",
      "actual_response": "Starr Pass",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.4400069378316402e-05,
        "tree_retrieval": 4.670345521066338,
        "debate": 126.78467150300276,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 131.65623404202051,
      "bert_score": 0.8157386779785156,
      "f1_score": 0.13793103448275862,
      "rouge_score": 0.12903225806451613,
      "bleurt_score": -0.7404652833938599
    },
    {
      "query": "Besides obtaining money, what is another purpose of using bribes against others?",
      "predicted_response": "harm",
      "method": "exact-match",
      "actual_response": "harm",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.409994628280401e-05,
        "tree_retrieval": 4.861955453059636,
        "debate": 126.78467150300276,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 5.091165459016338,
      "bert_score": 0.9999998211860657,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9087929129600525
    },
    {
      "query": "For how long was a king elected in the Roman Kingdom?",
      "predicted_response": "life term",
      "method": "exact-match",
      "actual_response": "life term",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.100000321865082e-05,
        "tree_retrieval": 4.384685144992545,
        "debate": 126.78467150300276,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.569562792079523,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0329148769378662
    },
    {
      "query": "Who was the prominent political leader who criticized The Times in 1944 for not backing the British Army?",
      "predicted_response": "Winston Churchill",
      "method": "exact-match",
      "actual_response": "Winston Churchill",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8399983420968056e-05,
        "tree_retrieval": 4.4577224149834365,
        "debate": 126.78467150300276,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.686011041048914,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9458638429641724
    },
    {
      "query": "In what year did The Russian Revolution occur?",
      "predicted_response": "1917",
      "method": "exact-match",
      "actual_response": "1917",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.15000070258975e-05,
        "tree_retrieval": 4.460797667969018,
        "debate": 126.78467150300276,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.686261957976967,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8707802295684814
    },
    {
      "query": "What was the number of Chinese troops participating in the rescue efforts?",
      "predicted_response": "135,000",
      "method": "exact-match",
      "actual_response": "135,000",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0399998649954796e-05,
        "tree_retrieval": 4.458843666012399,
        "debate": 126.78467150300276,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.688347790855914,
      "bert_score": 1.0000004768371582,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.01627516746521
    },
    {
      "query": "What is the US's total area in miles, as stated by the Encyclopedia Britannica?",
      "predicted_response": "3,676,486 sq mi",
      "method": "exact-match",
      "actual_response": "3,676,486 sq mi",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.090000245720148e-05,
        "tree_retrieval": 4.504740350996144,
        "debate": 126.78467150300276,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.656939374981448,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.1177921295166016
    },
    {
      "query": "Where in France was Cluny Abbey established?",
      "predicted_response": "M\u00e2con",
      "method": "exact-match",
      "actual_response": "M\u00e2con",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.160000778734684e-05,
        "tree_retrieval": 4.72406575398054,
        "debate": 126.78467150300276,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.91441574995406,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.7814981341362
    },
    {
      "query": "What did Josel request the city of Strasbourg to ban from being sold?",
      "predicted_response": "Luther's anti-Jewish works",
      "method": "exact-match",
      "actual_response": "Luther's anti-Jewish works",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.029999788850546e-05,
        "tree_retrieval": 4.459335803054273,
        "debate": 126.78467150300276,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.646104332990944,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0436159372329712
    },
    {
      "query": "Who moderated the initial debate between Bush and Kerry?",
      "predicted_response": "Jim Lehrer",
      "method": "exact-match",
      "actual_response": "Jim Lehrer",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8999987989664078e-05,
        "tree_retrieval": 4.465560268028639,
        "debate": 126.78467150300276,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.726140208076686,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9198075532913208
    },
    {
      "query": "What is the status of the Catalan Countries?",
      "predicted_response": "no official status",
      "method": "exact-match",
      "actual_response": "no official status",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1300936825573444e-05,
        "tree_retrieval": 4.573247438995168,
        "debate": 126.78467150300276,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.781791584100574,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.027785062789917
    },
    {
      "query": "When did the Persian Gulf War hostilities start?",
      "predicted_response": "Hostilities in the Persian Gulf War began on January 17th, but were part of a larger conflict known as Operation Desert Storm, which started on January 16th, and ended with a ceasefire declared by President Bush on February 24th, 1991.",
      "method": "debate",
      "actual_response": "January 1991",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.6300083845853806e-05,
        "tree_retrieval": 4.423301945091225,
        "debate": 75.39836269104853,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 80.0117593749892,
      "bert_score": 0.823395848274231,
      "f1_score": 0.10256410256410257,
      "rouge_score": 0.09523809523809523,
      "bleurt_score": -0.5273078680038452
    },
    {
      "query": "What became the student body's objective?",
      "predicted_response": "winning the big game",
      "method": "exact-match",
      "actual_response": "winning the big game",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.7499976567924023e-05,
        "tree_retrieval": 4.841051370021887,
        "debate": 75.39836269104853,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.994587416993454,
      "bert_score": 0.9999998211860657,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0807400941848755
    },
    {
      "query": "In what year was the Mann Act enacted?",
      "predicted_response": "June 25, 1910",
      "method": "exact-match",
      "actual_response": "June 25, 1910",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1400006264448166e-05,
        "tree_retrieval": 4.497910075937398,
        "debate": 75.39836269104853,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.7159444589633495,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.11072838306427
    },
    {
      "query": "What is the process for appointing judges?",
      "predicted_response": "elected by the voters",
      "method": "exact-match",
      "actual_response": "elected by the voters",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.2901065424084663e-05,
        "tree_retrieval": 4.607716288999654,
        "debate": 75.39836269104853,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.7837816250976175,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0817350149154663
    },
    {
      "query": "Who informed Mary that she would give birth to the Messiah?",
      "predicted_response": "Gabriel",
      "method": "exact-match",
      "actual_response": "Gabriel",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8700102120637894e-05,
        "tree_retrieval": 4.443892096052878,
        "debate": 75.39836269104853,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.686557832872495,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.7661246061325073
    },
    {
      "query": "Who established groups such as the FA?",
      "predicted_response": "Former public schoolboys",
      "method": "exact-match",
      "actual_response": "Former public schoolboys",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.3600954338908195e-05,
        "tree_retrieval": 4.51427868695464,
        "debate": 75.39836269104853,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.6802483750507236,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0528662204742432
    },
    {
      "query": "Which British king or queen is depicted above the frame surrounding the arches and entrance?",
      "predicted_response": "Queen Victoria",
      "method": "exact-match",
      "actual_response": "Queen Victoria",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.130000550299883e-05,
        "tree_retrieval": 4.402097321930341,
        "debate": 75.39836269104853,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.57905187504366,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.957355260848999
    },
    {
      "query": "What kind of philosopher was Hobbes?",
      "predicted_response": "empiricist",
      "method": "exact-match",
      "actual_response": "empiricist",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0399998649954796e-05,
        "tree_retrieval": 4.398039486957714,
        "debate": 75.39836269104853,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.55054079182446,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9779011011123657
    },
    {
      "query": "What is the current number of artworks housed in the National Museum?",
      "predicted_response": "315,678 artworks are housed in the National Museum across various galleries, reflecting European visual arts history from ancient frescoes to modern sculptures. The museum actively engages visitors through educational programs and community outreach initiatives. Its online catalogue provides detailed information about each artwork's historical significance and contemporary relevance.",
      "method": "debate",
      "actual_response": "200,000",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9199989512562752e-05,
        "tree_retrieval": 4.532004302018322,
        "debate": 154.30850009201095,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 159.13118358305655,
      "bert_score": 0.8034303188323975,
      "f1_score": 0,
      "rouge_score": 0.0,
      "bleurt_score": -0.2751266658306122
    },
    {
      "query": "Where is the Holiday Festival of Lights held?",
      "predicted_response": "James Island County Park",
      "method": "exact-match",
      "actual_response": "James Island County Park",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.140105400234461e-05,
        "tree_retrieval": 4.927908602054231,
        "debate": 154.30850009201095,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 5.1878898330032825,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9515003561973572
    },
    {
      "query": "During which war was Buckingham Palace left undamaged?",
      "predicted_response": "World War I",
      "method": "exact-match",
      "actual_response": "World War I",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.4699955247342587e-05,
        "tree_retrieval": 4.389894310967065,
        "debate": 154.30850009201095,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.541497249854729,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.1058157682418823
    },
    {
      "query": "What was IBM's 2004 operating margin?",
      "predicted_response": "16.8%",
      "method": "exact-match",
      "actual_response": "16.8%",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.9499991796910763e-05,
        "tree_retrieval": 4.629336487036198,
        "debate": 154.30850009201095,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.7875009579584,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0093518495559692
    },
    {
      "query": "Can you name a well-known restaurant in Little Havana?",
      "predicted_response": "Versailles",
      "method": "exact-match",
      "actual_response": "Versailles",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.989999484270811e-05,
        "tree_retrieval": 4.415841463953257,
        "debate": 154.30850009201095,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.628576625138521,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.7817168235778809
    },
    {
      "query": "In which year did the Tenth Doctor feature in the Sarah Jane series?",
      "predicted_response": "2009",
      "method": "exact-match",
      "actual_response": "2009",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.889998722821474e-05,
        "tree_retrieval": 4.472538645029999,
        "debate": 154.30850009201095,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.629408500157297,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.827873945236206
    },
    {
      "query": "When did Blair declare his resignation?",
      "predicted_response": "September 2006",
      "method": "exact-match",
      "actual_response": "September 2006",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0099996365606785e-05,
        "tree_retrieval": 4.577422561938874,
        "debate": 154.30850009201095,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.735711875138804,
      "bert_score": 0.9999996423721313,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9681576490402222
    },
    {
      "query": "Who became famous for his poor rendition of \"She Bangs\" during an audition?",
      "predicted_response": "William Hung gained fame with his unconventional rendition of \"She Bangs\" on American Idol, despite lacking musical competition wins. His off-key performance found widespread appeal through platforms like YouTube, amusing audiences and critics alike due to its humorous aspects, leading to extensive media attention.",
      "method": "debate",
      "actual_response": "William Hung",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1100003980100155e-05,
        "tree_retrieval": 4.4048629680182785,
        "debate": 129.42281802301295,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 133.97919724998064,
      "bert_score": 0.8412686586380005,
      "f1_score": 0.08695652173913045,
      "rouge_score": 0.0851063829787234,
      "bleurt_score": -0.8193164467811584
    },
    {
      "query": "What sustains the tree?",
      "predicted_response": "sapling-sized sprouts",
      "method": "exact-match",
      "actual_response": "sapling-sized sprouts",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.320001997053623e-05,
        "tree_retrieval": 4.792903047986329,
        "debate": 129.42281802301295,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 5.029603791888803,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0696970224380493
    },
    {
      "query": "What is the English translation of Zugunruhe?",
      "predicted_response": "migratory restlessness",
      "method": "exact-match",
      "actual_response": "migratory restlessness",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.090000245720148e-05,
        "tree_retrieval": 4.36555327498354,
        "debate": 129.42281802301295,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.523490499937907,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0424739122390747
    },
    {
      "query": "What occurred following Kanye's controversial remark?",
      "predicted_response": "Rick Kaplan cut off the microphone and then cut away to Chris Tucker",
      "method": "exact-match",
      "actual_response": "Rick Kaplan cut off the microphone and then cut away to Chris Tucker",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.920010592788458e-05,
        "tree_retrieval": 4.566385005018674,
        "debate": 129.42281802301295,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.744570292066783,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0608361959457397
    },
    {
      "query": "When did the Kievan state divide into twelve distinct principalities?",
      "predicted_response": "12th century,",
      "method": "exact-match",
      "actual_response": "12th century,",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.250001464039087e-05,
        "tree_retrieval": 4.396818671026267,
        "debate": 129.42281802301295,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.669322042027488,
      "bert_score": 0.9999997019767761,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.091225266456604
    },
    {
      "query": "What are Nigeria's religions apart from the two most prominent ones?",
      "predicted_response": "Nigeria is predominantly home to Christian and Muslim populations, with around 10% following indigenous or local religions deeply rooted in traditional customs. These beliefs contribute significantly to the nation's cultural mosaic. Religious diversity is common in many African countries where multiple faith systems often coexist harmoniously despite differences.",
      "method": "debate",
      "actual_response": "a tiny minority of adherents of Animism and other religions",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0099996365606785e-05,
        "tree_retrieval": 4.367788058007136,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 87.82592104189098,
      "bert_score": 0.837510883808136,
      "f1_score": 0.07142857142857142,
      "rouge_score": 0.06779661016949151,
      "bleurt_score": -0.012497142888605595
    },
    {
      "query": "What does the government of Saint Helena produce independently?",
      "predicted_response": "coinage and banknotes",
      "method": "exact-match",
      "actual_response": "coinage and banknotes",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.100000321865082e-05,
        "tree_retrieval": 4.821341909002513,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.9987336250487715,
      "bert_score": 0.9999999403953552,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0320954322814941
    },
    {
      "query": "In which location can the lake in Atenco be found?",
      "predicted_response": "Federal District",
      "method": "exact-match",
      "actual_response": "Federal District",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.279990050941706e-05,
        "tree_retrieval": 4.412007185979746,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.663720249896869,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9840481281280518
    },
    {
      "query": "To which other large agency's formation was the DHS likened?",
      "predicted_response": "the Department of Defense",
      "method": "exact-match",
      "actual_response": "the Department of Defense",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.100000321865082e-05,
        "tree_retrieval": 4.400440393015742,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.579356624977663,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0317355394363403
    },
    {
      "query": "What is the function of the Sieve of Eratosthenes?",
      "predicted_response": "compute primes",
      "method": "exact-match",
      "actual_response": "compute primes",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.95999925583601e-05,
        "tree_retrieval": 4.620369388954714,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.9092038332019,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0702271461486816
    },
    {
      "query": "Who is the creator of Minecraft?",
      "predicted_response": "Markus \"Notch\" Persson",
      "method": "exact-match",
      "actual_response": "Markus \"Notch\" Persson",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1800009310245514e-05,
        "tree_retrieval": 4.615360629977658,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.86431054212153,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9775742292404175
    },
    {
      "query": "On whose likeness was the ship on wheels modeled?",
      "predicted_response": "Nerthus or Freyr",
      "method": "exact-match",
      "actual_response": "Nerthus or Freyr",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.090000245720148e-05,
        "tree_retrieval": 4.406802821904421,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.583053166978061,
      "bert_score": 0.9999997615814209,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9856759309768677
    },
    {
      "query": "In which location do Eleonora's falcons nest?",
      "predicted_response": "Mediterranean islands",
      "method": "exact-match",
      "actual_response": "Mediterranean islands",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.090000245720148e-05,
        "tree_retrieval": 4.4058810049900785,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.560478999977931,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0079814195632935
    },
    {
      "query": "What features do certain dictionaries include?",
      "predicted_response": "sub-index",
      "method": "exact-match",
      "actual_response": "sub-index",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.070000093430281e-05,
        "tree_retrieval": 4.411051769042388,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.619648042134941,
      "bert_score": 1.0,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9534413814544678
    },
    {
      "query": "How is designing defined in the context of built environments?",
      "predicted_response": "architectural lighting design",
      "method": "exact-match",
      "actual_response": "architectural lighting design",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.099988680332899e-05,
        "tree_retrieval": 4.474168686079793,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.657577959122136,
      "bert_score": 1.0000003576278687,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.017285704612732
    },
    {
      "query": "What is the name of the LGBT newspaper?",
      "predicted_response": "Seattle Gay News",
      "method": "exact-match",
      "actual_response": "Seattle Gay News",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.120000474154949e-05,
        "tree_retrieval": 4.433152065961622,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.673146291868761,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9719201326370239
    },
    {
      "query": "What changes have occurred in the local dialects of French-speaking areas?",
      "predicted_response": "have almost disappeared",
      "method": "exact-match",
      "actual_response": "have almost disappeared",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.100000321865082e-05,
        "tree_retrieval": 4.427509346976876,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.579281624872237,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0763576030731201
    },
    {
      "query": "What makes this specific rule contentious?",
      "predicted_response": "the Fish and Wildlife Service (FWS) loses much ability to further protect a species if the mitigation measures by the landowner prove insufficient.",
      "method": "exact-match",
      "actual_response": "the Fish and Wildlife Service (FWS) loses much ability to further protect a species if the mitigation measures by the landowner prove insufficient.",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.8699985705316067e-05,
        "tree_retrieval": 4.627812647959217,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.909760957816616,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0176934003829956
    },
    {
      "query": "In which four years did England exit the UEFA European Championship at the group stage?",
      "predicted_response": "1980, 1988, 1992 and 2000",
      "method": "exact-match",
      "actual_response": "1980, 1988, 1992 and 2000",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.120000474154949e-05,
        "tree_retrieval": 4.521170233958401,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.7095522079616785,
      "bert_score": 1.0000001192092896,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.0484496355056763
    },
    {
      "query": "Who was interred in the abbey on April 4, 1727?",
      "predicted_response": "Isaac Newton",
      "method": "exact-match",
      "actual_response": "Isaac Newton",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 5.3900061175227165e-05,
        "tree_retrieval": 4.413041327032261,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.625714207999408,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8779375553131104
    },
    {
      "query": "What vanished and was later reconstructed to play period music?",
      "predicted_response": "authentic instruments",
      "method": "exact-match",
      "actual_response": "authentic instruments",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.95999925583601e-05,
        "tree_retrieval": 4.4067470140289515,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.558532708091661,
      "bert_score": 1.0000007152557373,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9698896408081055
    },
    {
      "query": "Which is one of the most challenging derbies held in Egypt?",
      "predicted_response": "The Cairo Derby",
      "method": "exact-match",
      "actual_response": "The Cairo Derby",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.0399998649954796e-05,
        "tree_retrieval": 4.459849641076289,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.611538915894926,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9872046709060669
    },
    {
      "query": "In which article by Donnelly and Embrechts did warnings and research on CDOs first appear?",
      "predicted_response": "2006",
      "method": "exact-match",
      "actual_response": "2006",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 2.6399968191981316e-05,
        "tree_retrieval": 4.43498811207246,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.634285500040278,
      "bert_score": 0.9999998807907104,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.8033155798912048
    },
    {
      "query": "Who is the focal point of all mystical experiences?",
      "predicted_response": "Christ",
      "method": "exact-match",
      "actual_response": "Christ",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.1400006264448166e-05,
        "tree_retrieval": 4.47337649599649,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.708839291008189,
      "bert_score": 0.9999995827674866,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 0.9097690582275391
    },
    {
      "query": "What are the components of gastric juice?",
      "predicted_response": "hydrochloric acid and pepsin",
      "method": "exact-match",
      "actual_response": "hydrochloric acid and pepsin",
      "source": "rajpurkar/squad",
      "latency": {
        "retrieval_table": 3.170000854879618e-05,
        "tree_retrieval": 4.736639939947054,
        "debate": 83.25850344006903,
        "global_llm": 1.5779120239894837
      },
      "overall_latency": 4.983117999974638,
      "bert_score": 1.000000238418579,
      "f1_score": 1.0,
      "rouge_score": 1.0,
      "bleurt_score": 1.002150535583496
    }
  ]
}